{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0e10f",
   "metadata": {},
   "source": [
    "# To save surface wind diagnostics into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.procc import *\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem, ttest_ind\n",
    "from windrose import WindroseAxes\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import sys\n",
    "from windrose import WindroseAxes\n",
    "from metpy import calc\n",
    "from metpy.units import units\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa96809",
   "metadata": {},
   "source": [
    "## Function to process files into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procFiles(for_direc, file_type, byDate = False, end_year = ''):\n",
    "    \n",
    "    file_dict = {}\n",
    "    # dates = ['0346','0952']\n",
    "    \n",
    "    #creates a dictionary with the file name as the key and the path of the file as the value\n",
    "    if byDate==True:\n",
    "        for root, dirs, filenames in os.walk(for_direc):\n",
    "            for file in filenames:\n",
    "                if file.endswith(\".nc\") and file_type in file and any(date in file for date in dates): #** (aijlh1) change format depending on scaleacc processing, may have to add enddate so doesn't go to 0101-1953, also aij\n",
    "                    file_to_add = os.path.join(root + '/', file) \n",
    "                    file_dict[file] = file_to_add\n",
    "    else:\n",
    "        for root, dirs, filenames in os.walk(for_direc):\n",
    "            for file in filenames:\n",
    "                if file.endswith(\".nc\") and file_type in file: #** (aijlh1) change format depending on scaleacc processing, may have to add enddate so doesn't go to 0101-1953, also aij\n",
    "                    file_to_add = os.path.join(root + '/', file) \n",
    "                    file_dict[file] = file_to_add\n",
    "\n",
    "                       \n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenLoL(arr): #flatten list of lists\n",
    "    flat_arr = []\n",
    "    \n",
    "    for list in arr:\n",
    "        for val in list:\n",
    "            flat_arr.append(val)\n",
    "\n",
    "    return flat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879665c",
   "metadata": {},
   "source": [
    "## Assign constants and obtain input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64751ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fensal eastern edge = 2.0 lat, 2.5 lon\n",
    "# fensal center = 2.0 lat, - 52.5 lon\n",
    "# shangrila eastern edge = -6.0 lat, -142.5\n",
    "# shangrila center = -6.0 lat, -177.5 lon\n",
    "# belet eastern edge = 2.0 lat, 142.5 lon\n",
    "# belet center = 2.0 lat, 107.5 lon\n",
    "z = 10 # (meters) where wind data is calculated\n",
    "k = 0.4 # van Karman constant\n",
    "z0 = 6*10**-4 # fensal surface roughness at equator ~= 0.0006 m\n",
    "coeff = np.log(z/z0)*1/k\n",
    "loc=''\n",
    "\n",
    "# UF =[0.01, 0.02, 0.03, 0.04]\n",
    "\n",
    "#UT = [uf*24.3 for uf in UF] # 24.3 from log wind profile equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62505c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = str(sys.argv[1])\n",
    "file_type = str(sys.argv[2])            # aijlh1\n",
    "byDate = sys.argv[3].lower() == 'true' \n",
    "multiYear = sys.argv[4].lower() == 'true'\n",
    "run = str(sys.argv[5])\n",
    "start_year = str(sys.argv[6])\n",
    "end_year = str(sys.argv[7])\n",
    "UF = float(sys.argv[8])\n",
    "zonal = sys.argv[9].lower() == 'true'\n",
    "\n",
    "if not zonal:\n",
    "    region = str(sys.argv[10]).lower()\n",
    "    location = str(sys.argv[11]).lower()\n",
    "    lat = str(sys.argv[12])\n",
    "    lon = str(sys.argv[13])\n",
    "    loc = [(lat,lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dcd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not zonal:\n",
    "    \n",
    "    reg_nam = ''\n",
    "    loc_nam = ''\n",
    "\n",
    "    if region == 'belet':\n",
    "        region = 'Belet/'\n",
    "        reg_nam = 'Belet'\n",
    "    elif region == 'shangrila':\n",
    "        region = 'ShangriLa/'\n",
    "        reg_nam = 'Shang'\n",
    "    elif region == 'fensal':\n",
    "        region = 'Fensal/'\n",
    "        reg_nam = 'Fen'\n",
    "    elif region == 'equator timestep':\n",
    "        region = 'Equator/Timestep/'\n",
    "\n",
    "\n",
    "\n",
    "    if region == 'equator timestep':\n",
    "        pass\n",
    "    elif location == 'center':\n",
    "        location = 'Center/'\n",
    "        loc_nam = 'C'\n",
    "    elif location == 'edge':\n",
    "        location = 'EastEdge/'\n",
    "        loc_nam = 'E'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(loc)>0:\n",
    "    name = reg_nam + loc_nam + '_' + run + '_' + str(UF)[2:] + '_' + start_year[2:] + str(int(end_year[2:])-1)+'_la' + str(int(float(loc[0][0]))) + 'lo'+str((float(loc[0][1]))).replace('.','p')\n",
    "elif zonal:\n",
    "    name = run + '_' + str(UF)[2:] + '_' + start_year[2:] + str(int(end_year[2:])-1) + '_' + 'Zonal'\n",
    "else:\n",
    "    name = run + '_' + str(UF)[2:] + '_' + start_year[2:] + str(int(end_year[2:])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a518674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveloc = \"/home/maxqc/Python/data/\" + run + '/' + region + location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "procDirec = procFiles(direc, file_type, byDate, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if end_year:\n",
    "#     corrected_dict = {}\n",
    "#     for key in sorted(procDirec.keys()):\n",
    "#         if end_year not in key:\n",
    "#             corrected_dict[key] = procDirec[key]\n",
    "#         else:\n",
    "#             break\n",
    "#     procDirec = corrected_dict\n",
    "\n",
    "if multiYear == True:\n",
    "    name = name + 'MY' \n",
    "    year = 0\n",
    "    year_dict = {}\n",
    "    text = 'Year'+str(year)\n",
    "    year_dict[text] = {}\n",
    "    \n",
    "    \n",
    "    for key in sorted(procDirec.keys()):\n",
    "        \n",
    "        if end_year and key[0:4] == end_year:\n",
    "            break\n",
    "            \n",
    "        file = procDirec[key]\n",
    "            \n",
    "        if key[0:4] != start_year:\n",
    "            start_year = key[0:4]\n",
    "            year+=1\n",
    "            text='Year'+str(year)\n",
    "            year_dict[text] = {}\n",
    "\n",
    "            \n",
    "        year_dict[text][key] = file\n",
    "\n",
    "    procDirec = year_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "if byDate == True:\n",
    "    name = name + 'byDate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3790b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindStatsTS(procDirec, UT, level = '', zonal = False, loc = [('-2','-2.5'),('-2','2.5'),('2','2.5'),('2','-2.5')]):\n",
    "    \n",
    "    WAll = []\n",
    "    DirAll = []\n",
    "    UAll = []\n",
    "    VAll = []\n",
    "    UAllYears = []\n",
    "    VAllYears = []\n",
    "    AllRDD = []\n",
    "    AllDP = []\n",
    "    AllDP_STD = []\n",
    "    AllDP_STDERR = []\n",
    "    \n",
    "    if zonal:\n",
    "        \n",
    "        lats = np.arange(-90., 91., 4)\n",
    "        lons = np.arange(-177.5, 177.6, 5)\n",
    "        \n",
    "        for key in sorted(procDirec.keys()):\n",
    "\n",
    "            U = []\n",
    "            V = []\n",
    "\n",
    "            for lat in lats:\n",
    "                \n",
    "                U_temp = []\n",
    "                V_temp = []\n",
    "                \n",
    "                for lon in lons:\n",
    "                    \n",
    "                    try: # except as some days are empty (jk doesn't seem to be the case anymore)\n",
    "                        with xr.open_dataset(procDirec[key]) as ds:\n",
    "                            \n",
    "                            if level:\n",
    "                                \n",
    "                                U_temp.append(ds.u.sel(lat=lat, lon=lon, level=level))\n",
    "\n",
    "                                V_temp.append(ds.v.sel(lat=lat,lon=lon, level=level))\n",
    "                                \n",
    "                            else:\n",
    "                                \n",
    "                                U_temp.append(ds.us.sel(lat=lat, lon=lon))\n",
    "\n",
    "                                V_temp.append(ds.vs.sel(lat=lat,lon=lon))\n",
    "                            \n",
    "                    except ValueError: # had issue with day not having values (jk)\n",
    "                        pass\n",
    "                \n",
    "                U.append(flattenLoL(U_temp))\n",
    "                V.append(flattenLoL(V_temp))\n",
    "                \n",
    "            # len(U) = 46\n",
    "            # len(U[0]) = first latitude and all longitude = 55152 = 766*72\n",
    "\n",
    "            U = np.mean(U,axis=0)\n",
    "            V = np.mean(V,axis=0)\n",
    "            \n",
    "            print(len(U))\n",
    "            print()\n",
    "            print(U)\n",
    "\n",
    "            UAll.append(U) # one day, 766\n",
    "            VAll.append(V)\n",
    "\n",
    "            metU = units.Quantity(U, \"m/s\")\n",
    "            metV = units.Quantity(V, \"m/s\")\n",
    "\n",
    "            #Dir=np.mod(np.rad2deg(np.arctan2(U, V)),360) # 'to' direction\n",
    "\n",
    "            Dir = [calc.wind_direction(metU[i], metV[i], convention='to') for i in range(0,len(V))]\n",
    "            Dir = [np.rad2deg(float(Dir[i])) for i in range(0,len(Dir))]\n",
    "\n",
    "            W = np.array([np.sqrt((U[i]**2) + (V[i]**2)) for i in range(0,len(U))])\n",
    "\n",
    "            bins=[]\n",
    "            windbins = np.arange(0,361,22.5)\n",
    "            deg_midP = [(windbins[i]+windbins[i+1])/2 for i in range(0,len(windbins)-1)]\n",
    "\n",
    "            for i in range(0,len(windbins)-1):\n",
    "                if i == len(windbins)-1:\n",
    "                    bins.append((xr.where((Dir>=windbins[i]) & (Dir<=windbins[i+1]), True, False)))\n",
    "                else:\n",
    "                    bins.append((xr.where((Dir>=windbins[i]) & (Dir<windbins[i+1]), True, False)))\n",
    "\n",
    "\n",
    "            t = xr.where(W>UT,1,0)\n",
    "            total=len(t)\n",
    "            cum_sum = sum(t)\n",
    "            t = float(cum_sum/total)\n",
    "\n",
    "            bins = [(np.ma.masked_equal((bins[i]*W),0)).compressed() for i in range(0,len(bins))]\n",
    "\n",
    "            binnedWavg = [np.mean(bins[i], axis=0) for i in range(0,len(bins))]\n",
    "\n",
    "            binnedDP = [(binnedWavg[i]**2 * (binnedWavg[i] - UT) * t) / 100. for i in range(0,len(bins))]\n",
    "\n",
    "            bin_DP = [(binnedDP[i], windbins[i]) for i in range(0,len(windbins))]\n",
    "\n",
    "            C = [binnedDP[i]*np.sin(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "            D = [binnedDP[i]*np.cos(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "\n",
    "            C = np.nansum(C)\n",
    "            D = np.nansum(D)\n",
    "\n",
    "            DP = np.nansum(binnedDP)\n",
    "\n",
    "            DP_STDERR = sem(binnedDP,nan_policy='omit')\n",
    "            DP_STD = np.nanstd(binnedDP)\n",
    "\n",
    "            RDP = np.sqrt((C**2) + (D**2))\n",
    "\n",
    "            RDD = np.mod((np.rad2deg(np.arctan2(D,C))*-1)+90,360) # clockwise from northward\n",
    "\n",
    "\n",
    "            AllDP.append(DP)\n",
    "            AllRDD.append(RDD)\n",
    "            AllDP_STD.append(DP_STD)\n",
    "            AllDP_STDERR.append(DP_STDERR)\n",
    "            WAll.append(W)\n",
    "            DirAll.append(Dir)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        for key in sorted(procDirec.keys()):\n",
    "\n",
    "            U = []\n",
    "            V = []\n",
    "\n",
    "            for lat,lon in loc:\n",
    "                try: # except as some days are empty (jk)\n",
    "                    with xr.open_dataset(procDirec[key]) as ds:\n",
    "\n",
    "                            U.append(ds.us.sel(lat=lat, lon=lon))\n",
    "\n",
    "                            V.append(ds.vs.sel(lat=lat,lon=lon))\n",
    "\n",
    "                except ValueError: # had issue with day not having values (jk)\n",
    "                    pass\n",
    "\n",
    "            #if len(loc) > 1: # average if multiple latitudes (i.e. square around equator)\n",
    "            U = np.mean(U,axis=0)\n",
    "            V = np.mean(V,axis=0)\n",
    "\n",
    "            UAll.append(U) # one day, 766\n",
    "            VAll.append(V)\n",
    "\n",
    "            metU = units.Quantity(U, \"m/s\")\n",
    "            metV = units.Quantity(V, \"m/s\")\n",
    "\n",
    "            #Dir=np.mod(np.rad2deg(np.arctan2(U, V)),360) # 'to' direction\n",
    "\n",
    "            Dir = [calc.wind_direction(metU[i], metV[i], convention='to') for i in range(0,len(V))]\n",
    "            Dir = [np.rad2deg(float(Dir[i])) for i in range(0,len(Dir))]\n",
    "\n",
    "            W = np.array([np.sqrt((U[i]**2) + (V[i]**2)) for i in range(0,len(U))])\n",
    "\n",
    "            bins=[]\n",
    "            windbins = np.arange(0,361,22.5)\n",
    "            deg_midP = [(windbins[i]+windbins[i+1])/2 for i in range(0,len(windbins)-1)]\n",
    "\n",
    "            for i in range(0,len(windbins)-1):\n",
    "                if i == len(windbins)-1:\n",
    "                    bins.append((xr.where((Dir>=windbins[i]) & (Dir<=windbins[i+1]), True, False)))\n",
    "                else:\n",
    "                    bins.append((xr.where((Dir>=windbins[i]) & (Dir<windbins[i+1]), True, False)))\n",
    "\n",
    "\n",
    "            t = xr.where(W>UT,1,0)\n",
    "            total=len(t)\n",
    "            cum_sum = sum(t)\n",
    "            t = float(cum_sum/total)\n",
    "\n",
    "            bins = [(np.ma.masked_equal((bins[i]*W),0)).compressed() for i in range(0,len(bins))]\n",
    "\n",
    "            binnedWavg = [np.mean(bins[i], axis=0) for i in range(0,len(bins))]\n",
    "\n",
    "            binnedDP = [(binnedWavg[i]**2 * (binnedWavg[i] - UT) * t) / 100. for i in range(0,len(bins))]\n",
    "\n",
    "            bin_DP = [(binnedDP[i], windbins[i]) for i in range(0,len(windbins))]\n",
    "\n",
    "            C = [binnedDP[i]*np.sin(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "            D = [binnedDP[i]*np.cos(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "\n",
    "            C = np.nansum(C)\n",
    "            D = np.nansum(D)\n",
    "\n",
    "            DP = np.nansum(binnedDP)\n",
    "\n",
    "            DP_STDERR = sem(binnedDP,nan_policy='omit')\n",
    "            DP_STD = np.nanstd(binnedDP)\n",
    "\n",
    "            RDP = np.sqrt((C**2) + (D**2))\n",
    "\n",
    "            RDD = np.mod((np.rad2deg(np.arctan2(D,C))*-1)+90,360) # clockwise from northward\n",
    "\n",
    "\n",
    "            AllDP.append(DP)\n",
    "            AllRDD.append(RDD)\n",
    "            AllDP_STD.append(DP_STD)\n",
    "            AllDP_STDERR.append(DP_STDERR)\n",
    "            WAll.append(W)\n",
    "            DirAll.append(Dir)\n",
    "\n",
    "    \n",
    "    return WAll, DirAll, UAll, VAll, AllDP, AllRDD, AllDP_STD, AllDP_STDERR\n",
    "\n",
    "    #     # For calculation of threshold velocity at 10 m, need to figure out if right\n",
    "    #     # https://books.google.com.hk/books?hl=en&lr=&id=eaxTAVp9avkC&oi=fnd&pg=PA137&ots=5nAJ__p7CX&sig=_a4lg7V3Io9mrdCbMY3I7uW0HD4&redir_esc=y#v=onepage&q=threshold&f=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UT = UF*24.3\n",
    "\n",
    "if multiYear and zonal: # don't need \"and zonal\", included in function\n",
    "\n",
    "    \n",
    "    year = [str(1960+i) for i in range(0,11)]\n",
    "    multiYrDP = []\n",
    "    multiYrRDD = []\n",
    "    multiYrDP_STD = []\n",
    "    multiYrDP_STDERR = []\n",
    "    multiYrU = []\n",
    "    multiYrV = []\n",
    "    multiYrDir = []\n",
    "    multiYrW = []\n",
    "    year = [str(1960+i) for i in range(0,11)]\n",
    "    \n",
    "    for index, key in enumerate(procDirec.keys()):\n",
    "        \n",
    "        W, Dir, U, V, AllDP, AllRDD, AllDP_STD, AllDP_STDERR = WindStatsTS(procDirec[key], UT, \"1\", zonal)\n",
    "        \n",
    "        multiYrDP.append(AllDP) # list of 675 * 766 values * N years\n",
    "        multiYrRDD.append(AllRDD)\n",
    "        multiYrDP_STD.append(AllDP_STD)\n",
    "        multiYrDP_STDERR.append(AllDP_STDERR)\n",
    "        multiYrU.append(U)\n",
    "        multiYrV.append(V)\n",
    "        multiYrDir.append(Dir)\n",
    "        multiYrW.append(W)\n",
    "        \n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_DP.csv\", AllDP, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_RDD.csv\", AllRDD, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_DP_STD.csv\", AllDP_STD, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_DP_STDERR.csv\", AllDP_STDERR, delimiter=\",\")\n",
    "\n",
    "        \n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_U.csv\", U, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_V.csv\", V, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_Dir.csv\", Dir, delimiter=\",\")\n",
    "#         np.savetxt(saveloc+name+year[index]+\"TSt_W.csv\", W, delimiter=\",\")\n",
    "        \n",
    "    YrAvgDP = np.mean(multiYrDP,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgRDD = np.mean(multiYrRDD,axis=0)\n",
    "    YrAvgDP_STD = np.mean(multiYrDP_STD,axis=0)\n",
    "    YrAvgDP_STDERR = np.mean(multiYrDP_STDERR,axis=0)\n",
    "    \n",
    "    YrAvgU = np.mean(multiYrU,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgV = np.mean(multiYrV,axis=0)\n",
    "    YrAvgDir = np.mean(multiYrDir,axis=0)\n",
    "    YrAvgW = np.mean(multiYrW,axis=0)\n",
    "        \n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_U.csv\", YrAvgU, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"yrAvgTSt_V.csv\", yrAvgV, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_Dir.csv\", YrAvgDir, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_W.csv\", YrAvgW, delimiter=\",\")\n",
    "\n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_DP.csv\", YrAvgDP, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"yrAvgTSt_RDD.csv\", yrAvgRDD, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_DP_STD.csv\", YrAvgDP_STD, delimiter=\",\")\n",
    "#     np.savetxt(saveloc+name+\"YrAvgTSt_DP_STDERR.csv\", YrAvgDP_STDERR, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "UT = UF*24.3\n",
    "\n",
    "if multiYear and not zonal: \n",
    "    \n",
    "    # Flatten? first would flatten years, then days\n",
    "    \n",
    "    year = [str(1960+i) for i in range(0,11)]\n",
    "    multiYrDP = []\n",
    "    multiYrRDD = []\n",
    "    multiYrDP_STD = []\n",
    "    multiYrDP_STDERR = []\n",
    "    multiYrU = []\n",
    "    multiYrV = []\n",
    "    multiYrDir = []\n",
    "    multiYrW = []\n",
    "    year = [str(1960+i) for i in range(0,11)]\n",
    "    \n",
    "    for index, key in enumerate(procDirec.keys()):\n",
    "        \n",
    "        W, Dir, U, V, AllDP, AllRDD, AllDP_STD, AllDP_STDERR = WindStatsTS(procDirec[key], UT, loc)\n",
    "        \n",
    "        multiYrDP.append(AllDP) # list of 675 * 766 values * N years\n",
    "        multiYrRDD.append(AllRDD)\n",
    "        multiYrDP_STD.append(AllDP_STD)\n",
    "        multiYrDP_STDERR.append(AllDP_STDERR)\n",
    "        multiYrU.append(U)\n",
    "        multiYrV.append(V)\n",
    "        multiYrDir.append(Dir)\n",
    "        multiYrW.append(W)\n",
    "        \n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_DP.csv\", AllDP, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_RDD.csv\", AllRDD, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_DP_STD.csv\", AllDP_STD, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_DP_STDERR.csv\", AllDP_STDERR, delimiter=\",\")\n",
    "\n",
    "        \n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_U.csv\", U, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_V.csv\", V, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_Dir.csv\", Dir, delimiter=\",\")\n",
    "        np.savetxt(saveloc+name+year[index]+\"TSt_W.csv\", W, delimiter=\",\")\n",
    "        \n",
    "    YrAvgDP = np.mean(multiYrDP,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgRDD = np.mean(multiYrRDD,axis=0)\n",
    "    YrAvgDP_STD = np.mean(multiYrDP_STD,axis=0)\n",
    "    YrAvgDP_STDERR = np.mean(multiYrDP_STDERR,axis=0)\n",
    "    \n",
    "    YrAvgU = np.mean(multiYrU,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgV = np.mean(multiYrV,axis=0)\n",
    "    YrAvgDir = np.mean(multiYrDir,axis=0)\n",
    "    YrAvgW = np.mean(multiYrW,axis=0)\n",
    "        \n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_U.csv\", YrAvgU, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"yrAvgTSt_V.csv\", yrAvgV, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_Dir.csv\", YrAvgDir, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_W.csv\", YrAvgW, delimiter=\",\")\n",
    "\n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_DP.csv\", YrAvgDP, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"yrAvgTSt_RDD.csv\", yrAvgRDD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_DP_STD.csv\", YrAvgDP_STD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgTSt_DP_STDERR.csv\", YrAvgDP_STDERR, delimiter=\",\")\n",
    "    \n",
    "    # can just flatten after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if byDate and not multiYear and not zonals: \n",
    "    \n",
    "    AllDP, AllRDD, AllDP_STD, AllDP_STDERR = WindStatsTS(procDirec[key], UT)\n",
    "    \n",
    "    np.savetxt(saveloc+name+\"TSt_DP.csv\", AllDP, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"TSt_RDD.csv\", AllRDD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"TSt_DP_STD.csv\", AllDP_STD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"TSt_DP_STDERR.csv\", AllDP_STDERR, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# # defined command line options\n",
    "# # this also generates --help and error handling\n",
    "\n",
    "# CLI=argparse.ArgumentParser()\n",
    "\n",
    "# CLI.add_argument(\n",
    "#   \"--loc\",  # name on the CLI - drop the `--` for positional/required parameters\n",
    "#   nargs=\"*\",  # 0 or more values expected => creates a list\n",
    "#   type=tuple,\n",
    "#   default=[('-2','-2.5'),('-2','2.5'),('2','2.5'),('2','-2.5')],  # default if nothing is provided\n",
    "# )\n",
    "\n",
    "\n",
    "# # parse the command line\n",
    "# args = CLI.parse_args()\n",
    "# # access CLI options\n",
    "# print(\"loc: %r\" % args.loc)\n",
    "\n",
    "# loc = args.loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
