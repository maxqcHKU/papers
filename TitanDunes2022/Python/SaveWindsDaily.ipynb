{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92e8aba",
   "metadata": {},
   "source": [
    "# To save surface wind diagnostics into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37028031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.procc import *\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem, ttest_ind\n",
    "from windrose import WindroseAxes\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import sys\n",
    "from windrose import WindroseAxes\n",
    "from metpy import calc\n",
    "from metpy.units import units\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79038df7",
   "metadata": {},
   "source": [
    "## Function to process files into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d47769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procFiles(for_direc, file_type, byDate = False, end_year = ''):\n",
    "    \n",
    "    file_dict = {}\n",
    "    # dates = ['0346','0952']\n",
    "    \n",
    "    #creates a dictionary with the file name as the key and the path of the file as the value\n",
    "    if byDate==True:\n",
    "        for root, dirs, filenames in os.walk(for_direc):\n",
    "            for file in filenames:\n",
    "                if file.endswith(\".nc\") and file_type in file and any(date in file for date in dates): #** (aijlh1) change format depending on scaleacc processing, may have to add enddate so doesn't go to 0101-1953, also aij\n",
    "                    file_to_add = os.path.join(root + '/', file) \n",
    "                    file_dict[file] = file_to_add\n",
    "    else:\n",
    "        for root, dirs, filenames in os.walk(for_direc):\n",
    "            for file in filenames:\n",
    "                if file.endswith(\".nc\") and file_type in file: #** (aijlh1) change format depending on scaleacc processing, may have to add enddate so doesn't go to 0101-1953, also aij\n",
    "                    file_to_add = os.path.join(root + '/', file) \n",
    "                    file_dict[file] = file_to_add\n",
    "\n",
    "                       \n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb597764",
   "metadata": {},
   "source": [
    "## Assign constants and obtain input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fensal eastern edge = 2.0 lat, 2.5 lon\n",
    "# fensal center = 2.0 lat, - 52.5 lon\n",
    "# shangrila eastern edge = -6.0 lat, -142.5\n",
    "# shangrila center = -6.0 lat, -177.5 lon\n",
    "# belet eastern edge = 2.0 lat, 142.5 lon\n",
    "# belet center = 2.0 lat, 107.5 lon\n",
    "\n",
    "\n",
    "z = 10 # (meters) where wind data is calculated\n",
    "k = 0.4 # van Karman constant\n",
    "z0 = 6*10**-4 # fensal surface roughness at equator ~= 0.0006 m\n",
    "coeff = np.log(z/z0)*1/k\n",
    "\n",
    "UF =[0.005, 0.01, 0.15]\n",
    "\n",
    "#UT = [uf*24.3 for uf in UF] # 24.3 from log wind profile equation\n",
    "\n",
    "\n",
    "direc = str(sys.argv[1])\n",
    "byDate = sys.argv[2].lower() == 'true' \n",
    "multiYear = sys.argv[3].lower() == 'true'\n",
    "name = str(sys.argv[4])\n",
    "start_year = str(sys.argv[5])\n",
    "end_year = str(sys.argv[6])\n",
    "UF = float(sys.argv[7])\n",
    "region = str(sys.argv[8])\n",
    "location = str(sys.argv[9])\n",
    "lat = str(sys.argv[10])\n",
    "lon = str(sys.argv[11])\n",
    "\n",
    "loc = [(lat,lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_nam = ''\n",
    "loc_nam = ''\n",
    "\n",
    "if region == 'belet':\n",
    "    region = 'Belet/'\n",
    "    reg_nam = 'Belet'\n",
    "elif region == 'shangrila':\n",
    "    region = 'ShangriLa/'\n",
    "    reg_nam = 'Shang'\n",
    "elif region == 'fensal':\n",
    "    region = 'Fensal/'\n",
    "    reg_nam = 'Fen'\n",
    "elif region == 'equator timestep':\n",
    "    region = 'Equator/Timestep/'\n",
    "\n",
    "\n",
    "\n",
    "if region == 'equator timestep':\n",
    "    pass\n",
    "elif location == 'center':\n",
    "    location = 'Center/'\n",
    "    loc_name = 'C'\n",
    "elif location == 'edge':\n",
    "    location = 'EastEdge/'\n",
    "    loc_name = 'E'\n",
    "\n",
    "\n",
    "saveloc = \"/home/maxqc/Python/data/\" + region + location\n",
    "name = reg_name + loc_nam + '_' + name + '_' + str(UF)[2:] + '_' + start_year[2:] + str(int(end_year[2:])-1)+'_la' + str(int(float(loc[0][0]))) + 'lo'+str((float(loc[0][1]))).replace('.','p')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "procDirec = procFiles(direc,'aijh1', byDate, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if end_year:\n",
    "    corrected_dict = {}\n",
    "    for key in sorted(procDirec.keys()):\n",
    "        if end_year not in key:\n",
    "            corrected_dict[key] = procDirec[key]\n",
    "        else:\n",
    "            break\n",
    "    procDirec = corrected_dict\n",
    "\n",
    "if multiYear == True:\n",
    "    name = name + 'MY' \n",
    "    year = 0\n",
    "    year_dict = {}\n",
    "    text = 'Year'+str(year)\n",
    "    year_dict[text] = {}\n",
    "    \n",
    "    \n",
    "    for key in sorted(procDirec.keys()):\n",
    "        \n",
    "        if end_year and key[0:4] == end_year:\n",
    "            break\n",
    "            \n",
    "        file = procDirec[key]\n",
    "            \n",
    "        if key[0:4] != start_year:\n",
    "            start_year = key[0:4]\n",
    "            year+=1\n",
    "            text='Year'+str(year)\n",
    "            year_dict[text] = {}\n",
    "\n",
    "            \n",
    "        year_dict[text][key] = file\n",
    "\n",
    "procDirec = year_dict\n",
    "\n",
    "if byDate == True:\n",
    "    name = name + 'byDate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d216ae",
   "metadata": {},
   "source": [
    "## Define function to save wind statistic output at daily temporal resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindStats(procDirec, UT, loc = [('-2','-2.5'),('-2','2.5'),('2','2.5'),('2','-2.5')] ):\n",
    "    \n",
    "    U = []\n",
    "    V = []\n",
    "    AllRDD = []\n",
    "    AllDP = []\n",
    "    AllDP_STD = []\n",
    "    AllDP_STDERR = []\n",
    "    \n",
    "    for file in sorted(procDirec.keys()):\n",
    "        U = []\n",
    "        V = []\n",
    "        for lat,lon in loc:\n",
    "            with xr.open_dataset(procDirec[file]) as ds:\n",
    "\n",
    "                U.append(ds.us.sel(lat=lat, lon=lon))\n",
    "\n",
    "                V.append(ds.vs.sel(lat=lat,lon=lon))\n",
    "        \n",
    "        if len(loc) > 1:\n",
    "            U = np.mean(U,axis=0)\n",
    "            V = np.mean(V,axis=0)\n",
    "\n",
    "        metU = units.Quantity(U, \"m/s\")\n",
    "        metV = units.Quantity(V, \"m/s\")\n",
    "        \n",
    "        #Dir=np.mod(np.rad2deg(np.arctan2(U, V)),360) # 'to' direction\n",
    "        \n",
    "        Dir = [calc.wind_direction(metU[i], metV[i], convention='to') for i in range(0,len(U))]\n",
    "        Dir = [np.rad2deg(float(Dir[i])) for i in range(0,len(Dir))]\n",
    "\n",
    "        W = np.sqrt((U**2) + (V**2))\n",
    "        \n",
    "        bins=[]\n",
    "        windbins = np.arange(0,361,22.5)\n",
    "        deg_midP = [(windbins[i]+windbins[i+1])/2 for i in range(0,len(windbins)-1)]\n",
    "        #avgW = float(W.mean())\n",
    "\n",
    "        t = xr.where(W>UT,1,0)\n",
    "        total=len(t)\n",
    "        cum_sum = sum(t)\n",
    "        t = float(cum_sum/total)\n",
    "\n",
    "        # accurate w time and over each longitude or?\n",
    "        # binned_t = [xr.where(bins[i]>UT,1,0) for i in range(0,len(bins))]\n",
    "\n",
    "        for i in range(0,len(windbins)-1):\n",
    "            if i == len(windbins)-1:\n",
    "                bins.append((xr.where((Dir>=windbins[i]) & (Dir<=windbins[i+1]), True, False)))\n",
    "            else:\n",
    "                bins.append((xr.where((Dir>=windbins[i]) & (Dir<windbins[i+1]), True, False)))\n",
    "\n",
    "\n",
    "        bins = [(np.ma.masked_equal((bins[i]*W),0)).compressed() for i in range(0,len(bins))]\n",
    "\n",
    "\n",
    "        binnedWavg = [np.mean(bins[i], axis=0) for i in range(0,len(bins))]\n",
    "\n",
    "        binnedDP = [(binnedWavg[i]**2 * (binnedWavg[i] - UT) * t) / 100. for i in range(0,len(bins))]\n",
    "\n",
    "        C = [binnedDP[i]*np.sin(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "        D = [binnedDP[i]*np.cos(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "\n",
    "        C = np.nansum(C)\n",
    "        D = np.nansum(D)\n",
    "\n",
    "        DP = np.nansum(binnedDP)\n",
    "\n",
    "        DP_STDERR = sem(binnedDP,nan_policy='omit')\n",
    "        DP_STD = np.nanstd(binnedDP)\n",
    "\n",
    "        RDP = np.sqrt((C**2) + (D**2))\n",
    "\n",
    "        RDD = np.mod((np.rad2deg(np.arctan2(D,C))*-1)+90,360) # clockwise from northward\n",
    "\n",
    "\n",
    "        AllDP.append(DP)\n",
    "        AllRDD.append(RDD)\n",
    "        AllDP_STD.append(DP_STD)\n",
    "        AllDP_STDERR.append(DP_STDERR)\n",
    "\n",
    "    return U, V, W, Dir, AllDP, AllRDD, AllDP_STD, AllDP_STDERR\n",
    "\n",
    "        # For calculation of threshold velocity at 10 m, need to figure out if right\n",
    "        # https://books.google.com.hk/books?hl=en&lr=&id=eaxTAVp9avkC&oi=fnd&pg=PA137&ots=5nAJ__p7CX&sig=_a4lg7V3Io9mrdCbMY3I7uW0HD4&redir_esc=y#v=onepage&q=threshold&f=false\n",
    "    # only for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a6d7e",
   "metadata": {},
   "source": [
    "## Depending on user input, run and save wind statistic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "UT = UF*24.3\n",
    "\n",
    "if multiYear: \n",
    "    \n",
    "    multiYrDP = []\n",
    "    multiYrRDD = []\n",
    "    multiYrDP_STD = []\n",
    "    multiYrDP_STDERR = []\n",
    "    multiYrU = []\n",
    "    multiYrV = []\n",
    "    multiYrDir = []\n",
    "    multiYrW = []\n",
    "    \n",
    "    for key in procDirec.keys():\n",
    "        \n",
    "        U, V, W, Dir, AllDP, AllRDD, AllDP_STD, AllDP_STDERR = WindStats(procDirec[key], UT)\n",
    "        \n",
    "        multiYrDP.append(AllDP) # list of 675 values * years\n",
    "        multiYrRDD.append(AllRDD)\n",
    "        multiYrDP_STD.append(AllDP_STD)\n",
    "        multiYrDP_STDERR.append(AllDP_STDERR)\n",
    "        multiYrU.append(U)\n",
    "        multiYrV.append(V)\n",
    "        multiYrDir.append(Dir)\n",
    "        multiYrW.append(W)\n",
    "        \n",
    "        #len(AllDP) = 675\n",
    "        \n",
    "    YrAvgDP = np.mean(multiYrDP,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgRDD = np.mean(multiYrRDD,axis=0)\n",
    "    YrAvgDP_STD = np.mean(multiYrDP_STD,axis=0)\n",
    "    YrAvgDP_STDERR = np.mean(multiYrDP_STDERR,axis=0)\n",
    "    \n",
    "    YrAvgU = np.mean(multiYrU,axis=0) # list of averaged columns/years, 675 days\n",
    "    yrAvgV = np.mean(multiYrV,axis=0)\n",
    "    YrAvgDir = np.mean(multiYrDir,axis=0)\n",
    "    YrAvgW = np.mean(multiYrW,axis=0)\n",
    "\n",
    "    np.savetxt(saveloc+name+\"YrAvgU.csv\", YrAvgU, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"yrAvgV.csv\", yrAvgV, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgDir.csv\", YrAvgDir, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgW.csv\", YrAvgW, delimiter=\",\")\n",
    "\n",
    "    np.savetxt(saveloc+name+\"YrAvgDP.csv\", YrAvgDP, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"yrAvgRDD.csv\", yrAvgRDD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgDP_STD.csv\", YrAvgDP_STD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"YrAvgDP_STDERR.csv\", YrAvgDP_STDERR, delimiter=\",\")\n",
    "    \n",
    "    np.savetxt(saveloc+name+\"multiYrDP.csv\", multiYrDP, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrRDD.csv\", multiYrRDD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrDP_STD.csv\", multiYrDP_STD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrDP_STDERR.csv\", multiYrDP_STDERR, delimiter=\",\")\n",
    "    \n",
    "    np.savetxt(saveloc+name+\"multiYrU.csv\", multiYrU, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrV.csv\", multiYrV, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrDir.csv\", multiYrDir, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"multiYrW.csv\", multiYrW, delimiter=\",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "if byDate and not multiYear: \n",
    "    \n",
    "    AllDP, AllRDD, AllDP_STD, AllDP_STDERR = WindStats(procDirec[key], UT)\n",
    "    \n",
    "    np.savetxt(saveloc+name+\"DP.csv\", AllDP, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"RDD.csv\", AllRDD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"DP_STD.csv\", AllDP_STD, delimiter=\",\")\n",
    "    np.savetxt(saveloc+name+\"DP_STDERR.csv\", AllDP_STDERR, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be useful in the future for parsing command line arguments\n",
    "\n",
    "# # fensal eastern edge = 2.0 lat, 2.5 lon\n",
    "# # fensal center = 2.0 lat, - 52.5 lon\n",
    "# # shangrila eastern edge = -6.0 lat, -142.5\n",
    "# # shangrila center = -6.0 lat, -177.5 lon\n",
    "# # belet eastern edge = 2.0 lat, 142.5 lon\n",
    "# # belet center = 2.0 lat, 107.5 lon\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# # defined command line options\n",
    "# # this also generates --help and error handling\n",
    "\n",
    "# CLI=argparse.ArgumentParser()\n",
    "\n",
    "# CLI.add_argument(\n",
    "#   \"--loc\",  # name on the CLI - drop the `--` for positional/required parameters\n",
    "#   nargs=\"*\",  # 0 or more values expected => creates a list\n",
    "#   type=tuple,\n",
    "#   default=[('-2','-2.5'),('-2','2.5'),('2','2.5'),('2','-2.5')],  # default if nothing is provided\n",
    "# )\n",
    "\n",
    "\n",
    "# # parse the command line\n",
    "# args = CLI.parse_args()\n",
    "# # access CLI options\n",
    "# print(\"loc: %r\" % args.loc)\n",
    "\n",
    "# loc = args.loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
