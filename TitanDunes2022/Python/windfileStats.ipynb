{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.procc import *\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem, ttest_ind\n",
    "from windrose import WindroseAxes\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import sys\n",
    "from windrose import WindroseAxes, WindAxes\n",
    "#from metpy import calc\n",
    "#from metpy.units import units\n",
    "from scipy.signal import savgol_filter\n",
    "import csv\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# periapsis.....................01-15 - day 15\n",
    "# vernal equinox................03-46 - day 148 = 0 °\n",
    "# summer solstice...............06-51 - day 325 = 90 °\n",
    "# apsis.........................07-18 - day 352\n",
    "# autumnal equinox..............09-52 - day 508 = 180 °\n",
    "# winter solstice...............12-46 - day 668 = 270 °"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_lst = []\n",
    "start = 147\n",
    "for i in range(675):\n",
    "    start+=1\n",
    "    day_lst.append(start % 675)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestepSL = np.linspace(0,360,517050)\n",
    "dailySL = np.linspace(0,360,675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74849896",
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_eqDaily = dailySL[0]\n",
    "au_eqDaily = dailySL[360]\n",
    "\n",
    "ve_eqTS = timestepSL[0]\n",
    "au_eqTS = timestepSL[360*766]\n",
    "\n",
    "rollbackDay = (148-1)*-1\n",
    "rollbackTS = ((148*766)-1)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02849620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppercent(count, total):\n",
    "\n",
    "    perc=float(count/total)*100\n",
    "\n",
    "    text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "    print(text)\n",
    "\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDP(WAll, DirAll, UF):\n",
    "    \n",
    "    UT = UF * 24.3\n",
    "    \n",
    "    allDP = np.array([])\n",
    "    allDP_STDERR = np.array([])\n",
    "\n",
    "    for i in range(0,len(WAll)):\n",
    "\n",
    "        W = WAll[i]\n",
    "        Dir = DirAll[i]\n",
    "\n",
    "        bins=[]\n",
    "        windbins = np.arange(0,361,22.5)\n",
    "        deg_midP = [(windbins[i]+windbins[i+1])/2 for i in range(0,len(windbins)-1)]\n",
    "\n",
    "        for i in range(0,len(windbins)-1):\n",
    "            if i == len(windbins)-1:\n",
    "                bins.append((xr.where((Dir>=windbins[i]) & (Dir<=windbins[i+1]), True, False)))\n",
    "            else:\n",
    "                bins.append((xr.where((Dir>=windbins[i]) & (Dir<windbins[i+1]), True, False)))\n",
    "\n",
    "\n",
    "        t = xr.where(W>UT,1,0)\n",
    "        total=len(t)\n",
    "        cum_sum = sum(t)\n",
    "        t = float(cum_sum/total)\n",
    "\n",
    "        bins = [(np.ma.masked_equal((bins[i]*W),0)).compressed() for i in range(0,len(bins))]\n",
    "\n",
    "        binnedWavg = [np.mean(bins[i], axis=0) for i in range(0,len(bins))]\n",
    "\n",
    "        binnedDP = [(binnedWavg[i]**2 * (binnedWavg[i] - UT) * t) / 100. for i in range(0,len(bins))]\n",
    "\n",
    "        C = [binnedDP[i]*np.sin(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "        D = [binnedDP[i]*np.cos(np.deg2rad(deg_midP[i])) for i in range(0,len(binnedDP))]\n",
    "\n",
    "        C = np.nansum(C)\n",
    "        D = np.nansum(D)\n",
    "\n",
    "        if np.isnan(np.nansum(binnedDP)):\n",
    "            DP = 0.\n",
    "        else:\n",
    "            DP = np.nansum(binnedDP)\n",
    "\n",
    "        DP_STDERR = sem(binnedDP,nan_policy='omit')\n",
    "        DP_STD = np.nanstd(binnedDP)\n",
    "\n",
    "        allDP = np.append(DP, allDP)\n",
    "        allDP_STDERR = np.append(allDP_STDERR, DP_STDERR)\n",
    "\n",
    "        \n",
    "        fill = np.nanmean(allDP_STDERR)\n",
    "        allDP_STDERR = np.ma.masked_invalid(allDP_STDERR)\n",
    "        allDP_STDERR = np.ma.filled(allDP_STDERR,fill)\n",
    "\n",
    "        #clear_output()\n",
    "        \n",
    "    return allDP, allDP_STDERR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# total = len(runs) * len(regions) * len(locations) * len(UT)\n",
    "\n",
    "def dpArea(run, region='', location=''):\n",
    "    \n",
    "    dp_dict = {}\n",
    "    \n",
    "    if region == 'Equator':\n",
    "        location = \"\"\n",
    "        timestep = \"Timestep\"\n",
    "    else:\n",
    "        timestep = \"\"\n",
    "\n",
    "    ## Recalculating DP since issue with artifact in timeseries\n",
    "\n",
    "\n",
    "    W_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_W.csv')[0]\n",
    "    DIR_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_Dir.csv')[0]\n",
    "    \n",
    "    W = openCSV(W_path)\n",
    "    DIR = openCSV(DIR_path)\n",
    "    \n",
    "    allDP, allDP_STDERR = calcDP(W, DIR, 0.005)\n",
    "    \n",
    "    dp_dict['DP'] = allDP\n",
    "    dp_dict['DPSTDERR'] = allDP_STDERR \n",
    "    \n",
    "    return dp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcUSTAR(run, region='', location='', z0 = 0.0246, z = 10, k = 0.4):\n",
    "    \n",
    "    if region == 'Equator':\n",
    "        location = \"\"\n",
    "        timestep = \"Timestep\"\n",
    "    else:\n",
    "        timestep = \"\"\n",
    "\n",
    "    W_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_W.csv')[0]\n",
    "    \n",
    "    W = openCSV(W_path)\n",
    "    \n",
    "    W = np.array(flattenArray(W))\n",
    "\n",
    "    coeff = (1/np.log(z/z0))*k\n",
    "\n",
    "    u_star = coeff*W\n",
    "    \n",
    "    return u_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b53831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getData(run, region, filename, location = \"\", flatten = False):\n",
    "    \n",
    "    if region == 'Equator':\n",
    "        location = \"\"\n",
    "        timestep = \"Timestep\"\n",
    "    else:\n",
    "        timestep = \"\"\n",
    "    \n",
    "    path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'\\\n",
    "                     +run+'/'+region+'/'+timestep+location+'/*'+filename+'.csv')[0]\n",
    "    \n",
    "    dataset = openCSV(path)\n",
    "    \n",
    "    if flatten:\n",
    "        return flattenArray(dataset)\n",
    "    else:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122bacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makeDict(dict, run ,region='', locations='', DP=False, USTAR=False, fn=''):\n",
    "    \n",
    "    if DP:\n",
    "        if not locations:\n",
    "            dict[run] = dpArea(run, region)\n",
    "        else:\n",
    "            loc_dict = {}\n",
    "            for location in locations:\n",
    "                loc_dict[location] = dpArea(run, region, location)\n",
    "\n",
    "            dict[run] = loc_dict\n",
    "    \n",
    "    elif USTAR:\n",
    "        if not locations:\n",
    "            dict[run] = calcUSTAR(run, region)\n",
    "        else:\n",
    "            loc_dict = {}\n",
    "            for location in locations:\n",
    "                loc_dict[location] = calcUSTAR(run, region, location)\n",
    "\n",
    "            dict[run] = loc_dict\n",
    "    \n",
    "    else:\n",
    "        if not locations:\n",
    "            dict[run] = getData(run, region, fn, flatten=True)\n",
    "        else:\n",
    "            loc_dict = {}\n",
    "            for location in locations:\n",
    "                loc_dict[location] = getData(run, region, fn, location = location, flatten=True)\n",
    "            dict[run] = loc_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c4a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makeBoxPlot(dict, runs, location, xlabel, ylabel, bottom, top, show=False, \n",
    "                title = '', var = '', N=675, output = '', yticks = np.array([])):\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "\n",
    "    if var:\n",
    "        if location == 'Equator':\n",
    "            box1 = dict[runs[0]][var]\n",
    "            box2 = dict[runs[1]][var]\n",
    "            box3 = dict[runs[2]][var]\n",
    "            box4 = dict[runs[3]][var]\n",
    "        else:\n",
    "            box1 = dict[runs[0]][location][var]\n",
    "            box2 = dict[runs[1]][location][var]\n",
    "            box3 = dict[runs[2]][location][var]\n",
    "            box4 = dict[runs[3]][location][var]\n",
    "    elif location == 'Equator':\n",
    "        box1 = dict[runs[0]]\n",
    "        box2 = dict[runs[1]]\n",
    "        box3 = dict[runs[2]]\n",
    "        box4 = dict[runs[3]]\n",
    "    else:\n",
    "        box1 = dict[runs[0]][location]\n",
    "        box2 = dict[runs[1]][location]\n",
    "        box3 = dict[runs[2]][location]\n",
    "        box4 = dict[runs[3]][location]\n",
    "\n",
    "    # Generate some random indices that we'll use to resample the original data\n",
    "    # arrays. For code brevity, just use the same random indices for each array\n",
    "\n",
    "    data = [\n",
    "        box1,\n",
    "        box2,\n",
    "        box3,\n",
    "        box4\n",
    "        ]\n",
    "    \n",
    "#     color_dict =  {'patch_artist': True,\n",
    "#              'capprops': dict(color='k'),\n",
    "#              'medianprops': dict(color='k')}\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    #fig.canvas.manager.set_window_title(title)\n",
    "    fig.subplots_adjust(left=0.075, right=0.95, top=0.9, bottom=0.25)\n",
    "\n",
    "    bp = ax1.boxplot(data, notch=0, sym='+', vert=1, whis=1.5)\n",
    "    plt.setp(bp['boxes'], color='dimgrey')\n",
    "    plt.setp(bp['whiskers'], color='dimgrey')\n",
    "    plt.setp(bp['fliers'], color='dimgrey', marker='+')\n",
    "    plt.setp(bp['medians'], color='dimgrey')\n",
    "    plt.setp(bp['caps'], color='dimgrey')\n",
    "\n",
    "    # Add a horizontal grid to the plot, but make it very light in color\n",
    "    # so we can use it for reading data values but not be distracting\n",
    "    ax1.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "                   alpha=0.5)\n",
    "\n",
    "    if title:\n",
    "        ax1.set(\n",
    "            title=title\n",
    "        )\n",
    "        \n",
    "    ax1.set(\n",
    "        axisbelow=True,  # Hide the grid behind plot objects\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "    )\n",
    "\n",
    "    # Now fill the boxes with desired colors\n",
    "    num_boxes = len(data)\n",
    "    box_colors = ['skyblue']*num_boxes\n",
    "    medians = np.empty(num_boxes)\n",
    "    for i in range(num_boxes):\n",
    "        box = bp['boxes'][i]\n",
    "        box_x = []\n",
    "        box_y = []\n",
    "        for j in range(5):\n",
    "            box_x.append(box.get_xdata()[j])\n",
    "            box_y.append(box.get_ydata()[j])\n",
    "        box_coords = np.column_stack([box_x, box_y])\n",
    "        # Alternate between Dark Khaki and Royal Blue\n",
    "        \n",
    "        ax1.add_patch(Polygon(box_coords, facecolor=box_colors[i]))\n",
    "        \n",
    "        # Now draw the median lines back over what we just filled in\n",
    "\n",
    "        med = bp['medians'][i]\n",
    "        median_x = []\n",
    "        median_y = []\n",
    "        for j in range(2):\n",
    "            median_x.append(med.get_xdata()[j])\n",
    "            median_y.append(med.get_ydata()[j])\n",
    "            #ax1.plot(median_x, median_y, color = 'black',lw=2)\n",
    "        medians[i] = median_y[0]\n",
    "        \n",
    "        # Finally, overplot the sample averages, with horizontal alignment\n",
    "        # in the center of each box\n",
    "        ax1.plot(np.average(med.get_xdata()), np.average(data[i]),\n",
    "                 color='w', marker='X', markeredgecolor='k')\n",
    "\n",
    "    # Set the axes ranges and axes labels\n",
    "    ax1.set_xlim(0.5, num_boxes + 0.5)\n",
    "    top = top\n",
    "    bottom = bottom\n",
    "    ax1.set_ylim(bottom, top)\n",
    "    ax1.set_xticklabels(runs,\n",
    "                        rotation=45, fontsize=12)\n",
    "    if yticks.any():\n",
    "        ax1.set_yticks(yticks)\n",
    "\n",
    "    # Due to the Y-axis scale being different across samples, it can be\n",
    "    # hard to compare differences in medians across the samples. Add upper\n",
    "    # X-axis tick labels with the sample medians to aid in comparison\n",
    "    # (just use two decimal places of precision)\n",
    "    pos = np.arange(num_boxes) + 1\n",
    "    upper_labels = [str(round(s, 4)) for s in medians]\n",
    "    weights = ['bold', 'semibold']\n",
    "    for tick, label in zip(range(num_boxes), ax1.get_xticklabels()):\n",
    "        k = tick % 2\n",
    "        ax1.text(pos[tick], .95, upper_labels[tick],\n",
    "                 transform=ax1.get_xaxis_transform(),\n",
    "                 horizontalalignment='center', size='x-small',\n",
    "                 weight=weights[k], color='black')\n",
    "\n",
    "    # Finally, add a basic legend\n",
    "    fig.text(0.12, 0.2, 'x', color='white', backgroundcolor='dimgray',\n",
    "             weight='roman', size='small')\n",
    "    \n",
    "    fig.text(0.02, 0.2, ' Average Value', color='black', weight='roman',\n",
    "             size='x-small')\n",
    "\n",
    "    if output:\n",
    "        plt.savefig(output+'_boxp.png')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else: \n",
    "        plt.clf()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760aaaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter\n",
    "\n",
    "def compSeries(data1, data2, labels1, labels2, xlabel, ylabel, err1 = np.array([]), err2 = np.array([]), color1 = 'tab:blue', color2 = 'tab:orange', \n",
    "                   xticks = np.arange(0,361,30), yticks = np.array([]), ylim = np.array([]), output = ''):\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    x = dailySL\n",
    "    \n",
    "    yhat1 = savgol_filter(data1, 51, 3) # window size 51, polynomial order 3\n",
    "    yhat2 = savgol_filter(data2, 51, 3)\n",
    "    \n",
    "    if err1.any() and err2.any():\n",
    "        order = [0,2,1,3]\n",
    "        \n",
    "        data1_upper = data1 + err1\n",
    "        data1_lower = data1 - err1\n",
    "\n",
    "        data2_upper = data2 + err2\n",
    "        data2_lower = data2 - err2\n",
    "\n",
    "        plt.fill_between(x,np.roll(data1_upper,-147),np.roll(data1_lower,-147),alpha=0.2, color = color1, label = labels1[1])\n",
    "        plt.fill_between(x,np.roll(data2_upper,-147),np.roll(data2_lower,-147),alpha=0.2, color = color2, label = labels2[1])\n",
    "\n",
    "\n",
    "\n",
    "    else: \n",
    "        order = [2,0,3,1]\n",
    "        \n",
    "        plt.plot(dailySL, np.roll(data1,-147), lw = 1, color = color1, label = labels1[1], alpha = 0.2)\n",
    "        plt.plot(dailySL, np.roll(data2,-147), lw = 1, color = color2, label = labels2[1], alpha = 0.2)\n",
    "        \n",
    "    plt.plot(dailySL, np.roll(yhat1,-147), lw = 1.5, color = color1, label = labels1[0])\n",
    "    plt.plot(dailySL, np.roll(yhat2,-147), lw = 1.5, color = color2, label = labels2[0])\n",
    "    \n",
    "    plt.xlabel(xlabel)\n",
    "    plt.xticks(xticks)\n",
    "    \n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    if yticks.any():\n",
    "        plt.yticks(yticks)\n",
    "    if ylim.any():\n",
    "        plt.ylim(ylim)\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "    plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) \n",
    "    \n",
    "    plt.axvspan(ve_eqDaily - 10, ve_eqDaily + 10, color='orange', alpha=0.4)\n",
    "    plt.axvspan(au_eqDaily - 10, au_eqDaily + 10, color='orange', alpha=0.4)\n",
    "    \n",
    "    if output:\n",
    "        plt.savefig(output+'compTS.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f2d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def histPlot(VAR, xlabel = '', ylabel = 'Frequency', output = '', binwidth=[], bins=[]):\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    \n",
    "    if binwidth:\n",
    "    \n",
    "        ax = sns.histplot(VAR,\n",
    "                      binwidth=binwidth,\n",
    "                      kde=True,\n",
    "                      stat='density',\n",
    "                      element = 'bars',\n",
    "                      edgecolor = 'white')\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    \n",
    "    elif bins:\n",
    "        \n",
    "        ax = sns.histplot(VAR,\n",
    "                      bins=bins,\n",
    "                      kde=True,\n",
    "                      stat='density',\n",
    "                      element = 'bars',\n",
    "                      edgecolor = 'white')\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ax = sns.histplot(VAR,\n",
    "                      kde=True,\n",
    "                      stat='density',\n",
    "                      element = 'bars',\n",
    "                      edgecolor = 'white')\n",
    "        ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    \n",
    "    if output:\n",
    "        plt.savefig(output+'_HIST.png', bbox_inches='tight')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20695c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotWindrose(DIR, W, output = '', anchor = (1., 1.), show=False, bins = np.arange(0,3.1,0.3)):\n",
    "\n",
    "    plt.clf()\n",
    "    ax = WindroseAxes.from_ax(theta_labels=['E','NE','N','NW','W','SW','S','SE'])\n",
    "    ax.bar(DIR, W, bins = bins, opening=0.8, blowto = False, normed=True, edgecolor='white') \n",
    "    ax.set_legend(units='m s$^{-1}$',bbox_to_anchor = anchor)\n",
    "    \n",
    "    if output:\n",
    "        plt.savefig(output+'WRose.png', bbox_inches='tight')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()\n",
    "    \n",
    "\n",
    "    \n",
    "    #ax = WindAxes.from_ax()\n",
    "    #ax, params = ax.pdf(W, bins=bins)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77a04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assignDays(data):\n",
    "    \n",
    "    data_daily = []\n",
    "    \n",
    "    for i in range(0,675):\n",
    "        b = 766*i\n",
    "        e = 766*(i+1)\n",
    "        temp = data[b:e]\n",
    "        data_daily.append(temp)\n",
    "        \n",
    "    return data_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seriesPlot(data, ylabel, timescale, yticks = np.array([]), ylim = np.array([]), \\\n",
    "               output = '', average = False, error=np.array([])):\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6), dpi=100)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    if timescale.lower() == 'daily':\n",
    "        \n",
    "        x = dailySL\n",
    "        rb = rollbackDay\n",
    "        \n",
    "        plt.plot(x,np.roll(data,rb),linewidth=1,color='black')\n",
    "        plt.axvspan(ve_eqDaily - 10, ve_eqDaily + 10, color='orange', alpha=0.4)\n",
    "        plt.axvspan(au_eqDaily - 10, au_eqDaily + 10, color='orange', alpha=0.4)\n",
    "        plt.xlabel('Solar Longitude (°)')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xticks([0,90,180,270,360])\n",
    "\n",
    "    elif timescale.lower() == 'timestep':\n",
    "        \n",
    "        x = timestepSL\n",
    "        rb = rollbackTS\n",
    "        \n",
    "        if average:   \n",
    "            \n",
    "            data_daily = assignDays(data)\n",
    "            x = dailySL\n",
    "            rb = rollbackDay\n",
    "            \n",
    "            data = np.mean(data_daily,axis=1)\n",
    "        \n",
    "        plt.plot(x,np.roll(data,rb),linewidth=1,color='black')\n",
    "        plt.axvspan(ve_eqTS - 10, ve_eqTS + 10, color='orange', alpha=0.4)\n",
    "        plt.axvspan(au_eqTS - 10, au_eqTS + 10, color='orange', alpha=0.4)\n",
    "        plt.xlabel('Solar Longitude (°)')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xticks([0,90,180,270,360])\n",
    "        \n",
    "    if yticks.any():\n",
    "        plt.yticks(yticks)\n",
    "    if ylim.any():\n",
    "        plt.ylim(ylim)\n",
    "        \n",
    "    if error.any():\n",
    "        upper = data + error\n",
    "        lower = data - error\n",
    "        plt.fill_between(x,np.roll(upper,rb),np.roll(lower,rb),alpha=0.7,lw=2.5)\n",
    "        \n",
    "    if output:\n",
    "        plt.savefig(output+'_TS.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def countWesterlies(W, DIR, UT):\n",
    "    \n",
    "    wstly_ut_days = []\n",
    "    wstly_days = []\n",
    "\n",
    "    for i, day in enumerate(W):\n",
    "\n",
    "        for j, wind in enumerate(day):\n",
    "\n",
    "            deg = DIR[i][j] \n",
    "\n",
    "            if deg > 0. and deg < 180.:\n",
    "                wstly_days.append(i)\n",
    "\n",
    "                if wind>=UT:\n",
    "                    wstly_ut_days.append(i)\n",
    "                \n",
    "    return wstly_ut_days, wstly_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ea99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convDayToSL(arr):\n",
    "    convArr = [dailySL[day_lst.index(day)] for day in arr]\n",
    "    return convArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43d11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flattenArray(arr): #flatten list of lists\n",
    "    flat_arr = []\n",
    "    \n",
    "    for list in arr:\n",
    "        for val in list:\n",
    "            flat_arr.append(val)\n",
    "\n",
    "    return flat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e3878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def openCSV(fn):\n",
    "    array = []\n",
    "\n",
    "    with open(fn, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            remake_row = []\n",
    "            for num in row:\n",
    "                remake_row.append(float(num))\n",
    "            array.append(remake_row)\n",
    "\n",
    "    return np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51af903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## count++ per wind per day\n",
    "def plotWindFreq(W, DIR, UT, output = '', show = False):\n",
    "    \n",
    "    wstly_ut_days, wstly_days = countWesterlies(W, DIR, UT)\n",
    "    \n",
    "    SLdaysWUT = convDayToSL(wstly_ut_days)\n",
    "    SLdaysW = convDayToSL(wstly_days)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.style.use('seaborn-deep')\n",
    "\n",
    "    bins=np.linspace(8.,360.,45)\n",
    "\n",
    "    plt.hist([SLdaysW, SLdaysWUT], bins=15, label=['Westerly Winds Above Threshold','Total Westerly Winds'],\n",
    "             histtype = 'stepfilled', color = ['tab:cyan', 'tab:blue'],\n",
    "             weights=[np.ones(len(SLdaysW)) / len(SLdaysW), np.ones(len(SLdaysWUT)) / len(SLdaysWUT)])\n",
    "\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.xticks(np.arange(0.,361.,30))\n",
    "    plt.xlabel('Solar Longitude (°)')\n",
    "    plt.ylabel('Percent (%)')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    if output:\n",
    "        plt.savefig(output+'WFREQ.png', bbox_inches='tight')\n",
    "        \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7117586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zonalGusts(U):\n",
    "    \n",
    "    wmax = np.zeros(675)\n",
    "    emax = np.zeros(675)\n",
    "\n",
    "    #index for day too?\n",
    "\n",
    "    for index, day in enumerate(U):\n",
    "\n",
    "        westerly = []\n",
    "        easterly = []\n",
    "\n",
    "        for wind in day:\n",
    "            if wind > 0.:\n",
    "                westerly.append(wind)\n",
    "            else: \n",
    "                easterly.append(wind)\n",
    "\n",
    "        if westerly:\n",
    "            wmax[index] = np.max(westerly)\n",
    "\n",
    "\n",
    "        if easterly:\n",
    "            emax[index] = np.max(easterly)\n",
    "        \n",
    "    wmax = np.ma.masked_where(wmax == 0., wmax)\n",
    "    emax = np.ma.masked_where(emax == 0., emax)\n",
    "    \n",
    "    return wmax, emax\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363a43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotScatter(x1, x2, show=False, output = ''):\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    plt.scatter(dailySL, np.roll(np.abs(x1),-147),marker='.',label='Max Easterly Zonal Wind', color='tab:orange')\n",
    "    plt.scatter(dailySL, np.roll(x2,-147),marker='.',label='Max Westerly Zonal Wind', color='tab:blue')\n",
    "    \n",
    "    plt.xlabel('Solar Longitude (°)')\n",
    "    plt.ylabel('Wind Speed (m/s)')\n",
    "    \n",
    "    plt.xticks(np.arange(0.,361.,30))\n",
    "\n",
    "    plt.ylim([-0.05,0.6])\n",
    "    plt.yticks(np.arange(0.,0.7,0.1))\n",
    "    \n",
    "    plt.legend(loc ='upper right')\n",
    "    \n",
    "    \n",
    "    if output:\n",
    "        plt.savefig(output+'SCTR.png', bbox_inches='tight')\n",
    "        \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else: \n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c023b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['FL', 'WT', 'Z0', 'WTZ0']\n",
    "regions = ['Belet', 'Equator', 'Fensal', 'ShangriLa']\n",
    "locations = ['Center', 'EastEdge'] \n",
    "\n",
    "total = len(runs)*len(regions)*len(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bc98a",
   "metadata": {},
   "source": [
    "## Windroses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ac2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "                \n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Windrose (right this time I swear)/\"+ name\n",
    "\n",
    "            W_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_W.csv')[0]\n",
    "            DIR_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_Dir.csv')[0]\n",
    "            \n",
    "            W = openCSV(W_path)\n",
    "            DIR = openCSV(DIR_path)\n",
    "            \n",
    "            W = flattenArray(W)\n",
    "            DIR = flattenArray(DIR)\n",
    "            \n",
    "            print(\"Current: \", W_path)\n",
    "            print(\"Current: \", DIR_path)\n",
    "            \n",
    "            plotWindrose(DIR, W, anchor = (-0.12,0.6), output = output)\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'W'\n",
    "            \n",
    "            histPlot(W, xlabel = 'Wind Speed (m/s)', binwidth=0.025, output = output)\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'DIR'\n",
    "            \n",
    "            histPlot(DIR, xlabel = 'Direction (°)', binwidth=5, output = output)\n",
    "                \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "            \n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8180c3",
   "metadata": {},
   "source": [
    "## Zonal Winds Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ebe8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "                \n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            U_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_U.csv')[0]\n",
    "            \n",
    "            U = openCSV(U_path)\n",
    "            \n",
    "            U = flattenArray(U)\n",
    "            \n",
    "            westerly = [u for u in U if u>0.]\n",
    "            easterly = [u for u in U if u<0.]\n",
    "            \n",
    "            easterly = np.abs(easterly)\n",
    "            \n",
    "            print(\"Current: \", U_path)\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'WEST'\n",
    "            \n",
    "            histPlot(westerly, xlabel = 'Wind Speed (m/s)', binwidth=0.025, output = output)\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'EAST'\n",
    "            \n",
    "            histPlot(easterly, xlabel = 'Wind Speed (m/s)', binwidth=0.025, output = output)\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'ALL_U'\n",
    "            \n",
    "            histPlot(U, xlabel = 'Wind Speed (m/s)', binwidth=0.025, output = output)\n",
    "                \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "            \n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e01f3",
   "metadata": {},
   "source": [
    "## Drift Potential Windrose and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4126c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UT = ['001', '003', '004', '005', '006']\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations) * len(UT)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            for ut in UT:\n",
    "                if region == 'Equator':\n",
    "                    location = \"\"\n",
    "                    timestep = \"Timestep\"\n",
    "                else:\n",
    "                    timestep = \"\"\n",
    "\n",
    "                name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "                DP_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/BinnedDP/*'+ut+'_binDP.csv')[0]\n",
    "\n",
    "                DP = openCSV(DP_path)\n",
    "\n",
    "                DP = flattenArray(DP)\n",
    "\n",
    "                DIR_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/BinnedDP/*'+ut+'_binDIR.csv')[0]\n",
    "\n",
    "                DIR = openCSV(DIR_path)\n",
    "\n",
    "                DIR = flattenArray(DIR)\n",
    "\n",
    "                print(\"Current: \", DIR_path)\n",
    "                print(\"Current: \", DP_path)\n",
    "                \n",
    "                output = \"/Users/maxcollins/Desktop/organized images/Windrose (right this time I swear)/\"+ name + '_' + ut + '_DP' \n",
    "                \n",
    "                #plotWindrose(DIR, DP, anchor = (-0.12,0.6), output = output)\n",
    "\n",
    "                output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'DPDIR'\n",
    "\n",
    "                histPlot(DIR, xlabel = 'Drift Potential Direction (°)', bins=16, output = output)\n",
    "                \n",
    "                output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'DP'\n",
    "                \n",
    "                histPlot(DP, xlabel = 'Drift Potential (VU)', bins=16, output = output)\n",
    "\n",
    "                count+=1\n",
    "\n",
    "                perc=float(count/total)*100\n",
    "\n",
    "                text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "                print(text)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                \n",
    "                            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3277927",
   "metadata": {},
   "source": [
    "## Timeseries DP with uncertainty and highlight equinoxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0213dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fensal_dictDP = {}\n",
    "belet_dictDP = {}\n",
    "shangrila_dictDP = {}\n",
    "eq_dictDP = {}\n",
    "\n",
    "region_dictsDP = [belet_dictDP, eq_dictDP, fensal_dictDP, shangrila_dictDP]\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions)\n",
    "\n",
    "for index, region in enumerate(regions):\n",
    "    for run in runs:\n",
    "        \n",
    "        if region == 'Equator':\n",
    "            locations=''\n",
    "        else:\n",
    "            locations = ['Center', 'EastEdge']\n",
    "            \n",
    "        makeDict(region_dictsDP[index], run, region, locations=locations, DP=True)\n",
    "    \n",
    "        count+=1\n",
    "    \n",
    "        ppercent(count,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea44b89",
   "metadata": {},
   "source": [
    "#### Series plots for each seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dictsDP = [belet_dictDP, eq_dictDP, fensal_dictDP, shangrila_dictDP]\n",
    "region_names = ['Belet', 'Equator', 'Fensal', 'ShangriLa']\n",
    "locations = ['Center', 'EastEdge']\n",
    "runs = ['FL', 'WT', 'Z0', 'WTZ0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(region_dict) * len(runs) * len(locations)\n",
    "count=0\n",
    "\n",
    "for index, region_dict in enumerate(region_dicts):\n",
    "    for run in runs:\n",
    "        for location in locations:           \n",
    "            try:\n",
    "                y =  region_dict[run][location]['DP']\n",
    "                error = region_dict[run][location]['DPSTDERR']\n",
    "                name = \"{}_{}_{}_\".format(run,region_names[index],location)\n",
    "            except KeyError:\n",
    "                y =  region_dict[run]['DP']\n",
    "                error = region_dict[run]['DPSTDERR']\n",
    "                name = \"{}_{}_\".format(run,region_names[index])\n",
    "                \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/\"+ name + 'DP'\n",
    "            if region_names[index] == 'Belet' and location == 'EastEdge':\n",
    "                yticks = np.arange(0.,0.016,0.002)\n",
    "                ylim = np.array([0.,0.015])\n",
    "            elif region_names[index] == 'ShangriLa' and location == 'EastEdge':\n",
    "                yticks = np.arange(0.,0.026,0.002)\n",
    "                ylim = np.array([0.,0.025])\n",
    "            else:\n",
    "                yticks = np.arange(0.,0.013,0.002)\n",
    "                ylim = np.array([0.,0.012])\n",
    "                \n",
    "            seriesPlot(y,'Drift Potential (VU)','daily', output = output, yticks = yticks, ylim = ylim, error = error)\n",
    "            \n",
    "            plt.clf()\n",
    "            count+=1\n",
    "            \n",
    "            ppercent(count,total)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a4ed7",
   "metadata": {},
   "source": [
    "#### Comp series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbe51f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# region_dicts = [belet_dictDP, eq_dictDP, fensal_dictDP, shangrila_dictDP]\n",
    "# region_names = ['Belet', 'Equator', 'Fensal', 'ShangriLa']\n",
    "# locations = ['Center', 'EastEdge']\n",
    "# runs = ['FL', 'WT', 'Z0', 'WTZ0']\n",
    "\n",
    "comps = [('FL','WT'), ('FL','Z0'), ('WTZ0','Z0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7626a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "count=0\n",
    "total= len(region_dicts) * len(locations) * len(comps)\n",
    "\n",
    "for index, region_dict in enumerate(region_dictsDP):\n",
    "    for location in locations: \n",
    "        for comp in comps:\n",
    "           \n",
    "            if region_names[index] != 'Equator':\n",
    "                \n",
    "                name = \"{}{}_{}_{}_DP\".format(comp[0],comp[1],region_names[index],location)\n",
    "                \n",
    "                DP1 = region_dict[comp[0]][location]['DP']\n",
    "                DP2 = region_dict[comp[1]][location]['DP']\n",
    "\n",
    "                DP1_ERR = region_dict[comp[0]][location]['DPSTDERR']\n",
    "                DP2_ERR = region_dict[comp[1]][location]['DPSTDERR']\n",
    "\n",
    "            else:\n",
    "                \n",
    "                name = name = \"{}{}_{}_DP\".format(comp[0],comp[1],region_names[index])\n",
    "                \n",
    "                DP1 = region_dict[comp[0]]['DP']\n",
    "                DP2 = region_dict[comp[1]]['DP']\n",
    "\n",
    "                DP1_ERR = region_dict[comp[0]]['DPSTDERR']\n",
    "                DP2_ERR = region_dict[comp[1]]['DPSTDERR']\n",
    "\n",
    "            output = '/Users/maxcollins/Desktop/organized images/Timeseries/DP/Comparison/' + name\n",
    "\n",
    "            compSeries(DP1, DP2, [comp[0], comp[0]+' Standard Error'], [comp[1],comp[1]+' Standard Error'], \n",
    "                       'Solar Longitude (°)', 'Drift Potential (VU)' , err1 = DP1_ERR, err2 = DP2_ERR, xticks = np.arange(0,361,30),\n",
    "                       yticks = np.arange(0.,0.017,0.002), ylim = np.array([0.,0.017]), output = output)\n",
    "            count+=1\n",
    "            ppercent(count,total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059fd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "DP1 = belet_dictDP['FL']['EastEdge']['DP']\n",
    "#DP2 = belet_dictDP['WT']['EastEdge']['DP']\n",
    "DP3 = belet_dictDP['Z0']['EastEdge']['DP']\n",
    "#DP4 = belet_dictDP['WTZ0']['EastEdge']['DP']\n",
    "\n",
    "yhat1 = savgol_filter(DP1, 51, 3) # window size 51, polynomial order 3\n",
    "#yhat2 = savgol_filter(DP2, 51, 3) # window size 51, polynomial order 3\n",
    "yhat3 = savgol_filter(DP3, 51, 3) # window size 51, polynomial order 3\n",
    "#yhat4 = savgol_filter(DP4, 51, 3) # window size 51, polynomial order 3\n",
    "\n",
    "plt.plot(dailySL, np.roll(DP1,-147), lw = 1, alpha = 0.2,color = 'tab:orange')\n",
    "#plt.plot(dailySL, np.roll(DP2,-147), lw = 1.5, alpha = 0.2, color = 'tab:blue' )\n",
    "plt.plot(dailySL, np.roll(DP3,-147), lw = 1, alpha = 0.2,color = 'tab:purple')\n",
    "#plt.plot(dailySL, np.roll(DP4,-147), lw = 1.5, alpha = 0.2, color = 'tab:red' )\n",
    "\n",
    "plt.plot(x,np.roll(yhat1,-147),lw=1.2,color='tab:orange',label='FL')\n",
    "#plt.plot(x,np.roll(yhat2,-147),lw=1,color='tab:blue',label='WT')\n",
    "plt.plot(x,np.roll(yhat3,-147),lw=1.2,color='tab:purple',label='Z0')\n",
    "#plt.plot(x,np.roll(yhat4,-147),'--',lw=1,color='tab:red',label='WTZ0')\n",
    "\n",
    "plt.ylim([0.,0.016])\n",
    "plt.yticks(np.arange(0.,0.017,0.002))\n",
    "plt.xticks(np.arange(0,361,30))\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Drift Potential (VU)')\n",
    "plt.xlabel('Solar Longitude (°)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae3247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "#DP1 = belet_dictDP['FL']['EastEdge']['DP']\n",
    "DP2 = belet_dictDP['WT']['EastEdge']['DP']\n",
    "#DP3 = belet_dictDP['Z0']['EastEdge']['DP']\n",
    "DP4 = belet_dictDP['WTZ0']['EastEdge']['DP']\n",
    "\n",
    "#yhat1 = savgol_filter(DP1, 51, 3) # window size 51, polynomial order 3\n",
    "yhat2 = savgol_filter(DP2, 51, 3) # window size 51, polynomial order 3\n",
    "#yhat3 = savgol_filter(DP3, 51, 3) # window size 51, polynomial order 3\n",
    "yhat4 = savgol_filter(DP4, 51, 3) # window size 51, polynomial order 3\n",
    "\n",
    "#plt.plot(dailySL, np.roll(DP1,-147), lw = 1, alpha = 0.2,color = 'tab:orange')\n",
    "plt.plot(dailySL, np.roll(DP2,-147), lw = 1.5, alpha = 0.2, color = 'tab:blue' )\n",
    "#plt.plot(dailySL, np.roll(DP3,-147), lw = 1, alpha = 0.2,color = 'tab:blue')\n",
    "plt.plot(dailySL, np.roll(DP4,-147), lw = 1.5, alpha = 0.2, color = 'tab:red' )\n",
    "\n",
    "#plt.plot(x,np.roll(yhat1,-147),lw=1.2,color='tab:orange',label='FL')\n",
    "plt.plot(x,np.roll(yhat2,-147),lw=1,color='tab:blue',label='WT')\n",
    "#plt.plot(x,np.roll(yhat3,-147),lw=1.2,color='tab:red',label='Z0')\n",
    "plt.plot(x,np.roll(yhat4,-147),lw=1,color='tab:red',label='WTZ0')\n",
    "\n",
    "plt.ylim([0.,0.016])\n",
    "plt.yticks(np.arange(0.,0.017,0.002))\n",
    "plt.xticks(np.arange(0,361,30))\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Drift Potential (VU)')\n",
    "plt.xlabel('Solar Longitude (°)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd1792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(dailySL, np.roll(belet_dictDP['WTZ0']['Center']['DP'],-147), lw = 0.5, label = 'WTZ0')\n",
    "plt.plot(dailySL, np.roll(belet_dictDP['Z0']['Center']['DP'],-147), lw = 0.5, label = 'Z0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75607fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(dailySL, np.roll(belet_dictDP['FL']['Center']['DP'],-147), lw = 0.5, label = 'FL', color = 'tab:blue')\n",
    "plt.plot(dailySL, np.roll(belet_dictDP['WT']['Center']['DP'],-147), lw = 1, label = 'WT', color = 'tab:orange',alpha=0.5)\n",
    "#plt.plot(dailySL, np.roll(belet_dictDP['WTZ0']['Center']['DP'],-147), lw = 0.5, label = 'WTZ0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e714750",
   "metadata": {},
   "source": [
    "## RDD Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "\n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            RDD_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYyrAvgTSt_RDD.csv')[0]\n",
    "\n",
    "            RDD = openCSV(RDD_path)\n",
    "\n",
    "            RDD = flattenArray(RDD)\n",
    "\n",
    "            print(\"Current: \", RDD_path)\n",
    "\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name + 'RDD'\n",
    "\n",
    "            histPlot(RDD, xlabel = 'Resultant Drift Direction (°)', bins=np.arange(0,361,22.5), output = output)\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            ppercent(count,total)\n",
    "            \n",
    "            plt.clf()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba7e95",
   "metadata": {},
   "source": [
    "## RDD Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fensal_dictRDD = {}\n",
    "belet_dictRDD = {}\n",
    "shangrila_dictRDD = {}\n",
    "eq_dictRDD = {}\n",
    "\n",
    "region_dictsRDD = [belet_dictRDD, eq_dictRDD, fensal_dictRDD, shangrila_dictRDD]\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions)\n",
    "\n",
    "for index, region in enumerate(regions):\n",
    "    for run in runs:\n",
    "        \n",
    "        if region == 'Equator':\n",
    "            locations=''\n",
    "        else:\n",
    "            locations = ['Center', 'EastEdge']\n",
    "            \n",
    "        makeDict(region_dictsRDD[index], run, region, locations=locations, fn='*MYyrAvgTSt_RDD')\n",
    "    \n",
    "        count+=1\n",
    "    \n",
    "        ppercent(count,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ccece-cfc5-417c-ba2d-f20c6f22afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import diff\n",
    "dx = dailySL[1] - dailySL[0]\n",
    "y = belet_dictRDD['WT']['Center']\n",
    "dy = diff(y)/dx\n",
    "# plt.plot(dailySL[1:], np.roll(dy,rollbackDay))\n",
    "yhat1 = savgol_filter(dy, 25, 5) # window size 51, polynomial order 3\n",
    "plt.plot(dailySL[1:], np.roll(yhat1,rollbackDay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133435f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(region_dict) * len(runs) * len(locations)\n",
    "count=0\n",
    "\n",
    "for index, region_dict in enumerate(region_dicts):\n",
    "    for run in runs:\n",
    "        for location in locations:           \n",
    "            try:\n",
    "                y =  region_dict[run][location]\n",
    "                name = \"{}_{}_{}_\".format(run,region_names[index],location)\n",
    "            except TypeError:\n",
    "                y =  region_dict[run]\n",
    "                name = \"{}_{}_\".format(run,region_names[index])\n",
    "            \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/RDD/\"+region_names[index]+'/'+ name + 'RDD'\n",
    "            \n",
    "            yticks = np.arange(0,361,30)\n",
    "            ylim = np.array([0,360])\n",
    "            \n",
    "            seriesPlot(y,'Resultant Drift Direction (°)','daily', output = output, yticks = yticks, ylim = ylim)\n",
    "            \n",
    "            plt.clf()\n",
    "            count+=1\n",
    "            \n",
    "            ppercent(count,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4796628",
   "metadata": {},
   "source": [
    "#### RDD Comp Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aecf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_dictsRDD = [belet_dictRDD, eq_dictRDD, fensal_dictRDD, shangrila_dictRDD]\n",
    "# region_names = ['Belet', 'Equator', 'Fensal', 'ShangriLa']\n",
    "# locations = ['Center', 'EastEdge']\n",
    "# runs = ['FL', 'WT', 'Z0', 'WTZ0']\n",
    "\n",
    "comps = [('FL','WT'), ('FL','Z0'), ('WTZ0','Z0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27494cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "count=0\n",
    "total= len(region_dictsRDD) * len(locations) * len(comps)\n",
    "\n",
    "for index, region_dict in enumerate(region_dictsRDD):\n",
    "    for location in locations: \n",
    "        for comp in comps:\n",
    "           \n",
    "            if region_names[index] != 'Equator':\n",
    "                \n",
    "                name = \"{}{}_{}_{}_RDD\".format(comp[0],comp[1],region_names[index],location)\n",
    "                \n",
    "                RDD1 = region_dict[comp[0]][location]\n",
    "                RDD2 = region_dict[comp[1]][location]\n",
    "                \n",
    "                RDD1_ERR = [sem(region_dict[comp[0]][location])]*675\n",
    "                RDD2_ERR = [sem(region_dict[comp[1]][location])]*675\n",
    "\n",
    "            else:\n",
    "                \n",
    "                name = name = \"{}{}_{}_RDD\".format(comp[0],comp[1],region_names[index])\n",
    "                \n",
    "                RDD1 = region_dict[comp[0]]\n",
    "                RDD2 = region_dict[comp[1]]\n",
    "                \n",
    "                RDD1_ERR = [sem(region_dict[comp[0]])]*675\n",
    "                RDD2_ERR = [sem(region_dict[comp[1]])]*675\n",
    "\n",
    "            output = '/Users/maxcollins/Desktop/organized images/Timeseries/RDD/Comparison/' + name\n",
    "\n",
    "            compSeries(RDD1, RDD2, [comp[0], comp[0]+' Standard Error'], [comp[1], comp[1]+' Standard Error'], \n",
    "                       'Solar Longitude (°)', 'Resultant Drift Direction (°)' , err1 = np.array(RDD1_ERR), \n",
    "                       err2 = np.array(RDD2_ERR), xticks = np.arange(0,361,30), yticks = np.arange(0,361,30), \n",
    "                       ylim = np.array([0.,360.]), output = output)\n",
    "            count+=1\n",
    "            ppercent(count,total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = belet_dictRDD['FL']['Center']\n",
    "RDD2 = belet_dictRDD['WT']['Center']\n",
    "\n",
    "compSeries(RDD1, RDD2, ['Smoothed FL', 'FL'], ['Smoothed WT', 'WT'], \n",
    "           'Solar Longitude (°)', 'Resultant Drift Direction (°)' , xticks = np.arange(0,361,30),\n",
    "           yticks = np.arange(0,361,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = belet_dictRDD['FL']['EastEdge']\n",
    "RDD2 = belet_dictRDD['WT']['EastEdge']\n",
    "\n",
    "compSeries(RDD1, RDD2, ['Smoothed FL', 'FL'], ['Smoothed WT', 'WT'], \n",
    "           'Solar Longitude (°)', 'Resultant Drift Direction (°)' , xticks = np.arange(0,361,30),\n",
    "           yticks = np.arange(0,361,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = belet_dictRDD['FL']['EastEdge']\n",
    "RDD2 = belet_dictRDD['Z0']['EastEdge']\n",
    "\n",
    "compSeries(RDD1, RDD2, ['Smoothed FL', 'FL'], ['Smoothed Z0', 'Z0'], \n",
    "           'Solar Longitude (°)', 'Resultant Drift Direction (°)' , xticks = np.arange(0,361,30),\n",
    "           yticks = np.arange(0,361,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e21179",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = belet_dictRDD['WT']['EastEdge']\n",
    "RDD2 = belet_dictRDD['WTZ0']['EastEdge']\n",
    "\n",
    "compSeries(RDD1, RDD2, ['Smoothed WT', 'WT'], ['Smoothed WTZ0', 'WTZ0'], \n",
    "           'Solar Longitude (°)', 'Resultant Drift Direction (°)' , xticks = np.arange(0,361,30),\n",
    "           yticks = np.arange(0,361,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa9227",
   "metadata": {},
   "source": [
    "## Zonal Wind Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f43c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT = 0.005*24.3\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "\n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            U_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_U.csv')[0]\n",
    "            \n",
    "            U = openCSV(U_path)\n",
    "\n",
    "            U = np.array(flattenArray(U))\n",
    "\n",
    "            print(\"Current: \", U_path)\n",
    "\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/\"+ name + 'U'\n",
    "            \n",
    "            seriesPlot(U,'Wind Speed (m/s)','timestep', average=True, output = output)\n",
    "            \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "\n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb57c0",
   "metadata": {},
   "source": [
    "## Meridional Wind Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT = 0.005*24.3\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "\n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            V_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYyrAvgTSt_V.csv')[0]\n",
    "            \n",
    "            V = openCSV(V_path)\n",
    "\n",
    "            V = np.array(flattenArray(V))\n",
    "\n",
    "            print(\"Current: \", V_path)\n",
    "\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/\"+ name + 'V'\n",
    "            \n",
    "            seriesPlot(U,'Wind Speed (m/s)','timestep', average=True, output = output)\n",
    "            \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "\n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ea79d",
   "metadata": {},
   "source": [
    "## Wind Direction Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87153a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT = 0.005*24.3\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "\n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            DIR_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_Dir.csv')[0]\n",
    "            \n",
    "            DIR = openCSV(DIR_path)\n",
    "\n",
    "            DIR = np.array(flattenArray(DIR))\n",
    "\n",
    "            print(\"Current: \", DIR_path)\n",
    "\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/\"+ name + 'DIR'\n",
    "            \n",
    "            seriesPlot(DIR,'Wind Direction (°)','timestep', average=True, output = output)\n",
    "            \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "\n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd7d3e",
   "metadata": {},
   "source": [
    "## Wind Magnitude Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT = 0.005*24.3\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "\n",
    "            name = \"{}_{}_{}_\".format(run,region,location)\n",
    "\n",
    "            W_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_W.csv')[0]\n",
    "            \n",
    "            W = openCSV(W_path)\n",
    "\n",
    "            W = np.array(flattenArray(W))\n",
    "\n",
    "            print(\"Current: \", W_path)\n",
    "\n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Timeseries/\"+ name + 'W'\n",
    "            \n",
    "            seriesPlot(W,'Wind Speed (m/s)','timestep', average=True, output = output)\n",
    "            \n",
    "            count+=1\n",
    "\n",
    "            perc=float(count/total)*100\n",
    "\n",
    "            text = \"Percent completed: {:.2f}% \".format(perc)\n",
    "\n",
    "            print(text)\n",
    "\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2664781",
   "metadata": {},
   "source": [
    "## Frequency Days above Threshold\n",
    "### and when those days occur during the year i.e. if during equinox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF = np.array([0.005, 0.01, 0.02])\n",
    "UT = UF*24.3\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations) * len(UT)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "            for ut in UT:\n",
    "                \n",
    "                if region == 'Equator':\n",
    "                    location = \"\"\n",
    "                    timestep = \"Timestep\"\n",
    "                    name = \"{}_{}_{}_\".format(run,region,np.round(ut,2))\n",
    "                else:\n",
    "                    timestep = \"\"\n",
    "                    name = \"{}_{}_{}_{}_\".format(run,region,location,np.round(ut,2))\n",
    "\n",
    "                W_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_W.csv')[0]\n",
    "                DIR_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_Dir.csv')[0]\n",
    "\n",
    "                W = openCSV(W_path)\n",
    "\n",
    "                DIR = openCSV(DIR_path)\n",
    "\n",
    "                print(\"Current: \", W_path)\n",
    "                print(\"Current: \", DIR_path)\n",
    "\n",
    "                output = \"/Users/maxcollins/Desktop/organized images/Histograms/\"+ name\n",
    "\n",
    "                plotWindFreq(W, DIR, ut, output = output)\n",
    "                \n",
    "                count+=1\n",
    "\n",
    "                ppercent(count,total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b4ad8",
   "metadata": {},
   "source": [
    "## Gusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = len(runs) * len(regions) * len(locations)\n",
    "\n",
    "for run in runs:\n",
    "    for region in regions:\n",
    "        for location in locations:\n",
    "\n",
    "            if region == 'Equator':\n",
    "                location = \"\"\n",
    "                timestep = \"Timestep\"\n",
    "                name = \"{}_{}_gust\".format(run,region)\n",
    "            else:\n",
    "                timestep = \"\"\n",
    "                name = \"{}_{}_{}_gust\".format(run,region,location)\n",
    "\n",
    "            U_path = glob.glob('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+region+'/'+timestep+location+'/*MYYrAvgTSt_U.csv')[0]\n",
    "            \n",
    "            U = openCSV(U_path)\n",
    "            \n",
    "            print(\"Current: \", U_path)\n",
    "        \n",
    "            output = \"/Users/maxcollins/Desktop/organized images/Scatter/\"+ name\n",
    "            \n",
    "            wmax, emax = zonalGusts(U)\n",
    "            \n",
    "            plotScatter(emax, wmax, output = output)\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            ppercent(count,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc569e",
   "metadata": {},
   "source": [
    "## Box plot comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a06e7d",
   "metadata": {},
   "source": [
    "#### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb75868",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = np.arange(0,361,30)\n",
    "\n",
    "for index, region_dict in enumerate(region_dictsRDD):\n",
    "\n",
    "    for location in locations:\n",
    "        \n",
    "        if region_names[index]=='Equator':\n",
    "            location = 'Equator'\n",
    "            name = location + '_RDD'\n",
    "\n",
    "        else:\n",
    "            name = region_names[index] + location + '_RDD'\n",
    "\n",
    "        \n",
    "        output = '/Users/maxcollins/Desktop/organized images/Boxplots/' + name\n",
    "        \n",
    "        makeBoxPlot(region_dict, runs, location, 'Run', 'Resultant Drift Direction (°)', 0.0, 360., \n",
    "                    output = output, yticks = yticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a9671",
   "metadata": {},
   "source": [
    "#### DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32589a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yticks = np.arange(0,361,30)\n",
    "\n",
    "for index, region_dict in enumerate(region_dictsDP):\n",
    "\n",
    "    for location in locations:\n",
    "\n",
    "        plt.clf()\n",
    "        \n",
    "        if region_names[index]=='Equator':\n",
    "            location = 'Equator'\n",
    "            name = location + '_DP'\n",
    "\n",
    "        else:\n",
    "            name = region_names[index] + location + '_DP'\n",
    "\n",
    "        \n",
    "        output = '/Users/maxcollins/Desktop/organized images/Boxplots/' + name\n",
    "        \n",
    "        makeBoxPlot(region_dict, runs, location, 'Run', 'Drift Potential (VU)', 0.0, 0.015, \n",
    "                    output = output, var = 'DP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bf475",
   "metadata": {},
   "source": [
    "## Friction Speed Velocity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beletUSTAR = {}\n",
    "fensalUSTAR = {}\n",
    "shangrilaUSTAR = {}\n",
    "eqUSTAR = {}\n",
    "\n",
    "region_dictsUSTAR = [beletUSTAR, eqUSTAR, fensalUSTAR, shangrilaUSTAR]\n",
    "\n",
    "count = 0\n",
    "total = len(runs) * len(regions)\n",
    "\n",
    "for index, region in enumerate(regions):\n",
    "    for run in runs:\n",
    "        \n",
    "        if region == 'Equator':\n",
    "            locations=''\n",
    "        else:\n",
    "            locations = ['Center', 'EastEdge']\n",
    "            \n",
    "        makeDict(region_dictsUSTAR[index], run, region, locations=locations, USTAR = True)\n",
    "    \n",
    "        count+=1\n",
    "    \n",
    "        ppercent(count,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935668a-ad23-43a5-aef0-14e6a802067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqUSTAR['FL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a500a-3647-45c3-9842-143cdbc74d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "gfg = sns.histplot(eqUSTAR['FL'], bins=20, \n",
    "             common_norm = True, common_bins=True, stat = 'frequency', edgecolor='white', kde=True) # FL first\n",
    "\n",
    "plt.xlabel(\"Friction Speed\")\n",
    "\n",
    "plt.savefig('/Users/maxcollins/Desktop/organized images/Histograms/Friction Speed/FL_USTAR.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf245d-d999-4c37-b881-2f79dc758aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ustarHistComp(compdict, run1, run2, location, hue_order, output):\n",
    "    run = [run1]*len(compdict[run1][location])\n",
    "    run.extend(([run2]*len(compdict[run2][location])))\n",
    "    \n",
    "    ustar = np.concatenate((compdict[run1][location], compdict[run2][location]))\n",
    "    \n",
    "    d_ustar = {'Run': run, 'Friction Speed': ustar}\n",
    "    df_ustar = pd.DataFrame(data=d_ustar)\n",
    "    \n",
    "    plt.clf()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    gfg = sns.histplot(data=df_ustar, x=\"Friction Speed\", hue=\"Run\", multiple=\"layer\", bins=20, \n",
    "                 common_norm = True, common_bins=True, stat = 'frequency', edgecolor='white', hue_order=hue_order) # FL first\n",
    "    \n",
    "    plt.setp(gfg.get_legend().get_title(), fontsize='20') \n",
    "\n",
    "    plt.savefig('/Users/maxcollins/Desktop/organized images/Histograms/Friction Speed/'+output+'_USTAR.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9028c-d167-43ac-b6ea-3e35ec1f2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustarHistComp(fensalUSTAR, 'FL', 'Z0', 'EastEdge', ['FL','Z0'], 'fenEE_FLZ0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0469756",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = ['WT']*len(beletUSTAR['WT']['Center'])\n",
    "run.extend((['FL']*len(beletUSTAR['FL']['Center'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006baf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustar = np.concatenate((beletUSTAR['Z0']['Center'], beletUSTAR['FL']['Center'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b371aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ustar = {'Run': run, 'Friction Speed': ustar}\n",
    "df_ustar = pd.DataFrame(data=d_ustar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce479f-2e9b-4cbb-b237-dfbd30f1666d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "gfg = sns.histplot(data=df_ustar, x=\"Friction Speed\", hue=\"Run\", multiple=\"layer\", bins=20, \n",
    "             common_norm = True, common_bins=True, stat = 'frequency', edgecolor='white', hue_order=[\"FL\", \"Z0\"]) \n",
    "# for legend text\n",
    "#plt.setp(gfg.get_legend().get_texts(), fontsize='18') \n",
    " \n",
    "# for legend title\n",
    "plt.setp(gfg.get_legend().get_title(), fontsize='20') \n",
    "\n",
    "plt.savefig('/Users/maxcollins/Desktop/organized images/Histograms/Friction Speed/belC_FLZ0_USTAR.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d116c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Sand drift potential depends strongly on latitude and threshold friction - calculations with different grain size etc?\n",
    "# - Latitudinal distribution of observed dunes implies threshold friction speed close to 0.02 ms-1 (Lorenz et al. 2006)\n",
    "# - Allison (1992) threshold frictions speed 0.017 m s-1  for optimum sand diameter of 50 microns\n",
    "# - Lorenz et al. 1995 min threshold friction speed on present Titan 0.03-0.04 ms-1 for 200-300 micron diameter\n",
    "\n",
    "# The sand particle density is assumed to be 1000 kg m −3(Lorenz et al.,  1995), 0.02 m s−1 is most likely, \n",
    "# in accordance with Lorenz et al. (2006) . Allison (1992) calculated  the  threshold  friction  speed  as  0.017  m s − 1 for  \n",
    "# an optimum sand diameter of 50 μm, while Lorenz et al. (1995) obtained a minimum threshold friction speed \n",
    "# on present Titan as 0.03–0.04 m s−1for 200–300 μm diameter\n",
    "\n",
    "# Remember using threshold speed thats friction speed * 24.3 - also model output approximated closer to ground\n",
    "\n",
    "# - Likely particle diameter 100 to 300 microns (Lorenz et al. 2006)\n",
    "# - Threshold suspension fraction speed (Lorenz et al. 1995) varies between 0.08 and 0.3 ms-1\n",
    "# - Beyond tail of wind probability density function, neglect likelihood of dune destruction by excessive winds\n",
    "\n",
    "# - Basic factors that control formation of dunes are availability of sand, surface wind speed statistics, modality of wind direction (e.g.,Bagnold, 1941; Livingstone and Warren, 1996).\n",
    "# - Speeds high enough for saltation but low enough for dune formation \n",
    "\n",
    "\n",
    "# * Eq. (13), grain size influences roughness because grains are the discrete units from which the bed is composed and larger grains \n",
    "# produce rougher microtopography and hence greater drag on the boundary layer whether or not saltation is occurring.\n",
    "# * During saltation (i.e. when u⁎ − u⁎t> 0), an additional “saltation-induced” roughness occurs, represented by the second \n",
    "# term on the right side of Eq. (15). The magnitude of this effect increases with the excess shear velocity, because higher values \n",
    "# of excess shear velocity cause greater saltation. \n",
    "# https://click.endnote.com/viewer?doi=10.1016/j.geomorph.2008.10.010&route=5\n",
    "# * The aerodynamic “law of the wall ”states that the wind velocity profile above a rough surface is a function of the aerodynamic roughness length, which, during sal-tation, is a function of both grain size and excess shear velocity (Sherman, 1992)\n",
    "# * In areas of limited sand supply (i.e. partial sand cover), the aerodynamic roughness length will be at least partially controlled by the roughness elements (e.g. vegetation, alluvial deposits, and bedrock outcrops) that comprise the interdune or sand-free areas\n",
    "# * the aerodynamic roughness length will become progressively more influenced by the size of the roughness elements in the interdune areas (which generally have no relationship with the grain size of sand on the dunes)\n",
    "# J. D. Pelletier\n",
    "# * increase in bed shear stress is associated with the fact that, for relatively small roughness lengths, the wind velocities interacting with the bedforms will be greater (due to the higher velocity gradients associated with smaller roughness lengths), hence the degree of flow compression/expansion will also be greater\n",
    "# * At smaller roughness lengths (0.01 mm), the shear stress variation decreases, associated with increase in form drag and back pressure that limits near-surface wind velocities compared to cases with lower L/z0 ratios (L = half length of bedform)\n",
    "# Geomorphology\n",
    "# (2009)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f073c",
   "metadata": {},
   "source": [
    "## Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221385fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import iris\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "from iris.coords import DimCoord\n",
    "from iris.cube import Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topography = '/Users/maxcollins/Documents/Code/python/Input Files/test files/titan_topo.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b82a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(topography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run='WTZ0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = openCSV('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+run+'AIJu_grid.csv')\n",
    "v = openCSV('/Users/maxcollins/Documents/Code/python/data/'+run+'/'+run+'AIJv_grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = DimCoord(np.arange(-90., 91., 4),\n",
    "                    standard_name='latitude',\n",
    "                    units='degrees')\n",
    "longitude = DimCoord(np.arange(-177.5, 177.6, 5),\n",
    "                     standard_name='longitude',\n",
    "                     units='degrees')\n",
    "uwind = Cube(u, units='m/s',\n",
    "            dim_coords_and_dims=[(latitude, 0),\n",
    "                                 (longitude, 1)])\n",
    "\n",
    "uwind.rename('x_wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = DimCoord(np.arange(-90., 91., 4),\n",
    "                    standard_name='latitude',\n",
    "                    units='degrees')\n",
    "longitude = DimCoord(np.arange(-177.5, 177.6, 5),\n",
    "                     standard_name='longitude',\n",
    "                     units='degrees')\n",
    "vwind = Cube(v, units='m/s',\n",
    "            dim_coords_and_dims=[(latitude, 0),\n",
    "                                 (longitude, 1)])\n",
    "\n",
    "vwind.rename('y_wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = DimCoord(np.arange(-90., 91., 4),\n",
    "                    standard_name='latitude',\n",
    "                    units='degrees')\n",
    "longitude = DimCoord(np.arange(-177.5, 177.6, 5),\n",
    "                     standard_name='longitude',\n",
    "                     units='degrees')\n",
    "topog = Cube(np.array(ds.zatmo), units='m',\n",
    "            dim_coords_and_dims=[(latitude, 0),\n",
    "                                 (longitude, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "name = run+'_Vec'\n",
    "#plt.figure(figsize=(15,15), constrained_layout=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15), constrained_layout=True)\n",
    "\n",
    "X, Y = np.meshgrid(lats,lons)\n",
    "\n",
    "# Create a cube containing the wind speed.\n",
    "windspeed = (uwind ** 2 + vwind ** 2) ** 0.5\n",
    "windspeed.rename(\"windspeed\")\n",
    "\n",
    "# Plot the wind speed as a contour plot.\n",
    "if run != 'FL' and run != 'Z0':\n",
    "    levels=[-1000, -800, -600, -400,-200, 0, 100, 150]\n",
    "    qplt.contour(topog, colors='black', linewidths = 1.5, levels = levels, alpha=0.5)\n",
    "\n",
    "levels = np.arange(0.,1.61,0.2)\n",
    "qplt.contourf(windspeed, 20, cmap = 'hot_r', alpha=0.6, levels=levels)\n",
    "\n",
    "# Add arrows to show the wind vectors.\n",
    "\n",
    "plt.xlim([-180,180])\n",
    "plt.xticks([-180,-150,-120,-90,-60,-30,0,30,60,90,120,150,180])\n",
    "\n",
    "plt.yticks([-90,-60,-30,0,30,60,90])\n",
    "\n",
    "plt.title(\" \")\n",
    "\n",
    "plt.ylabel('Latitude (°N)')\n",
    "plt.xlabel('Longitude (°E)')\n",
    "plt.axis([-180,180,-60,60])\n",
    "\n",
    "\n",
    "plt.colorbar(orientation='vertical',pad=0.02,fraction=0.02, label='Wind Speed (m/s)', ticks=np.arange(0.,1.61,0.2))\n",
    "\n",
    "iplt.quiver(uwind, vwind, X, Y, pivot=\"middle\", scale=25, width=0.0015)\n",
    "\n",
    "plt.savefig('/Users/maxcollins/Desktop/organized images/Vectors/'+name+'.png', bbox_inches='tight')\n",
    "\n",
    "qplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0e738-b25e-4398-accc-7b378dfafde5",
   "metadata": {},
   "source": [
    "### T-Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a437c1-29d9-45ea-bc63-db1a0002e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t, p = ttest_ind(fensal_dictRDD['FL']['Center'], fensal_dictRDD['WT']['Center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a434e-c6bd-44d6-8b66-2dffe9ad520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsDict(var_dict, run1, location = '', var = ''):\n",
    "    \n",
    "    dict = {}\n",
    "    \n",
    "    runs = ['FL', 'WT', 'Z0', 'WTZ0']\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        if not location:\n",
    "            if var:\n",
    "                t, p = ttest_ind(var_dict[run1][var], var_dict[run][var])\n",
    "            else:\n",
    "                t, p = ttest_ind(var_dict[run1], var_dict[run])\n",
    "        else:\n",
    "            if var:\n",
    "                t, p = ttest_ind(var_dict[run1][location][var], var_dict[run][location][var])\n",
    "            else:\n",
    "                t, p = ttest_ind(var_dict[run1][location], var_dict[run][location])\n",
    "        \n",
    "        dict[run] = (t, p)\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b4880-946a-49d8-8db3-7b1049dc81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_dictsDP\n",
    "# region_dictsRDD = [belet_dictRDD, eq_dictRDD, fensal_dictRDD, shangrila_dictRDD]\n",
    "stats_RDD = {}\n",
    "stats_DP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b118d-9e55-4d37-9c19-f99665be0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, run in enumerate(runs):\n",
    "    loc_dict = {}\n",
    "    for location in locations:\n",
    "        if index != 1:\n",
    "            loc_dict[location] = statsDict(region_dictsRDD[index], run, location)\n",
    "        else:\n",
    "            loc_dict[location] = statsDict(region_dictsRDD[index], run)\n",
    "            \n",
    "    stats_RDD[run] = loc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6470f4-966e-46d2-b730-30b6702a2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs: \n",
    "    print(ttest_ind(belet_dictRDD['WT']['Center'], belet_dictRDD[run]['Center']))\n",
    "    \n",
    "print() \n",
    "    \n",
    "for run in runs: \n",
    "    print(ttest_ind(belet_dictRDD['WT']['EastEdge'], belet_dictRDD[run]['EastEdge']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf9e0f9-8aec-420d-a2cd-50a9b913b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, run in enumerate(runs):\n",
    "    \n",
    "    loc_dict = {}\n",
    "    \n",
    "    for location in locations:\n",
    "        if index != 1:\n",
    "            loc_dict[location] = statsDict(region_dictsDP[index], run, location, 'DP')\n",
    "        else:\n",
    "            loc_dict[location] = statsDict(region_dictsDP[index], run, 'DP')\n",
    "            \n",
    "    stats_DP[run] = loc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cfdfa-1c51-4de8-8b02-8e951f740708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
